{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Execute this block if your running this notebook in Colab"
      ],
      "metadata": {
        "id": "U8OnjCzwJn1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1iOQziZqU0v7eGaHnCZmdKEOHJP5idc_y\n",
        "!mkdir /root/.kaggle/\n",
        "!mv ./kaggle.json /root/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "!pip install -q kaggle\n",
        "!kaggle competitions download -c tabular-playground-series-aug-2022\n",
        "!unzip tabular-playground-series-aug-2022.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIYuVy1akYA_",
        "outputId": "773c0729-65f5-4116-95af-4dc2e0e0f37e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1iOQziZqU0v7eGaHnCZmdKEOHJP5idc_y\n",
            "To: /content/kaggle.json\n",
            "100% 64.0/64.0 [00:00<00:00, 81.9kB/s]\n",
            "Downloading tabular-playground-series-aug-2022.zip to /content\n",
            "  0% 0.00/2.27M [00:00<?, ?B/s]\n",
            "100% 2.27M/2.27M [00:00<00:00, 36.2MB/s]\n",
            "Archive:  tabular-playground-series-aug-2022.zip\n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Start from here if your running this notebook in other environments"
      ],
      "metadata": {
        "id": "p7Y93ybyJwYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install feature_engine"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nM_cWVERkFoM",
        "outputId": "add247df-eb80-44fb-87d6-6227f0f3f041"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting feature_engine\n",
            "  Downloading feature_engine-1.5.2-py2.py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.0/290.0 KB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (1.21.6)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (1.7.3)\n",
            "Requirement already satisfied: pandas>=1.0.3 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (1.3.5)\n",
            "Requirement already satisfied: statsmodels>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (0.12.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from feature_engine) (1.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.3->feature_engine) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0.3->feature_engine) (2022.7)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->feature_engine) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->feature_engine) (3.1.0)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.8/dist-packages (from statsmodels>=0.11.1->feature_engine) (0.5.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from patsy>=0.5->statsmodels>=0.11.1->feature_engine) (1.15.0)\n",
            "Installing collected packages: feature_engine\n",
            "Successfully installed feature_engine-1.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTMLawnZcdJo"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, BatchNormalization, Dense, Dropout, concatenate\n",
        "from tensorflow.nn import sigmoid\n",
        "from tensorflow.keras.activations import swish\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow as tf\n",
        "from sklearn.linear_model import HuberRegressor\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from feature_engine.encoding import WoEEncoder\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "pd.options.display.max_columns = 999"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"train.csv\")\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "submission = pd.read_csv(\"sample_submission.csv\")"
      ],
      "metadata": {
        "id": "cGpiIoksi6EF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [ref] https://www.kaggle.com/code/purist1024/principled-3-vs-2-cv-splitting-on-product-code\n",
        "folds_dict = {f'Fold 1': [['C', 'D', 'E'], ['A', 'B']], \n",
        "               'Fold 2': [['B', 'D', 'E'], ['A', 'C']],\n",
        "               'Fold 3': [['B', 'C', 'E'], ['A', 'D']],\n",
        "               'Fold 4': [['B', 'C', 'D'], ['A', 'E']],\n",
        "               'Fold 5': [['A', 'D', 'E'], ['B', 'C']],\n",
        "               'Fold 6': [['A', 'C', 'E'], ['B', 'D']],\n",
        "               'Fold 7': [['A', 'C', 'D'], ['B', 'E']],\n",
        "               'Fold 8': [['A', 'B', 'E'], ['C', 'D']],\n",
        "               'Fold 9': [['A', 'B', 'D'], ['C', 'E']],\n",
        "               'Fold 10': [['A', 'B', 'C'], ['D', 'E']]}"
      ],
      "metadata": {
        "id": "BUivmShqttFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(df_train, df_test):\n",
        "    data = pd.concat([df_train, df_test])\n",
        "    \n",
        "    data['m3_missing'] = data['measurement_3'].isnull().astype(np.int8)\n",
        "    data['m5_missing'] = data['measurement_5'].isnull().astype(np.int8)\n",
        "    data['area'] = data['attribute_2'] * data['attribute_3']\n",
        "\n",
        "    feature = [f for f in df_test.columns if f.startswith('measurement') or f=='loading']\n",
        "\n",
        "    \n",
        "    full_fill_dict = dict()\n",
        "    full_fill_dict['measurement_17'] = {\n",
        "        'A': ['measurement_5','measurement_6','measurement_8'],\n",
        "        'B': ['measurement_4','measurement_5','measurement_7'],\n",
        "        'C': ['measurement_5','measurement_7','measurement_8','measurement_9'],\n",
        "        'D': ['measurement_5','measurement_6','measurement_7','measurement_8'],\n",
        "        'E': ['measurement_4','measurement_5','measurement_6','measurement_8'],\n",
        "        'F': ['measurement_4','measurement_5','measurement_6','measurement_7'],\n",
        "        'G': ['measurement_4','measurement_6','measurement_8','measurement_9'],\n",
        "        'H': ['measurement_4','measurement_5','measurement_7','measurement_8','measurement_9'],\n",
        "        'I': ['measurement_3','measurement_7','measurement_8']\n",
        "    }\n",
        "\n",
        "    \n",
        "    col = [col for col in df_test.columns if 'measurement' not in col]+ ['loading','m3_missing','m5_missing']\n",
        "    a = []\n",
        "    b =[]\n",
        "    for x in range(3,17):\n",
        "        corr = np.absolute(data.drop(col, axis=1).corr()[f'measurement_{x}']).sort_values(ascending=False)\n",
        "        a.append(np.round(np.sum(corr[1:4]),3))\n",
        "        b.append(f'measurement_{x}')\n",
        "    c = pd.DataFrame()\n",
        "    c['Selected columns'] = b\n",
        "    c['correlation total'] = a\n",
        "    c = c.sort_values(by = 'correlation total',ascending=False).reset_index(drop = True)\n",
        "\n",
        "    for i in range(10):\n",
        "        measurement_col = 'measurement_' + c.iloc[i,0][12:]\n",
        "        fill_dict = {}\n",
        "        for x in data.product_code.unique() : \n",
        "            corr = np.absolute(data[data.product_code == x].drop(col, axis=1).corr()[measurement_col]).sort_values(ascending=False)\n",
        "            measurement_col_dic = {}\n",
        "            measurement_col_dic[measurement_col] = corr[1:5].index.tolist()\n",
        "            fill_dict[x] = measurement_col_dic[measurement_col]\n",
        "        full_fill_dict[measurement_col] =fill_dict\n",
        "\n",
        "    feature = [f for f in data.columns if f.startswith('measurement') or f=='loading']\n",
        "    nullValue_cols = [col for col in df_train.columns if df_train[col].isnull().sum()!=0]\n",
        "\n",
        "    for code in data.product_code.unique():\n",
        "        total_na_filled_by_linear_model = 0\n",
        "        for measurement_col in list(full_fill_dict.keys()):\n",
        "            tmp = data[data.product_code == code]\n",
        "            column = full_fill_dict[measurement_col][code]\n",
        "            tmp_train = tmp[column+[measurement_col]].dropna(how='any')\n",
        "            tmp_test = tmp[(tmp[column].isnull().sum(axis=1)==0)&(tmp[measurement_col].isnull())]\n",
        "\n",
        "            model = HuberRegressor(epsilon=1.9)\n",
        "            model.fit(tmp_train[column], tmp_train[measurement_col])\n",
        "            data.loc[(data.product_code==code)&(data[column].isnull().sum(axis=1)==0)&(data[measurement_col].isnull()),measurement_col] = model.predict(tmp_test[column])\n",
        "            print(f'{measurement_col} : {len(tmp_test)}')\n",
        "            total_na_filled_by_linear_model += len(tmp_test)\n",
        "\n",
        "        # non-numeric columns:\n",
        "        NA = data.loc[data[\"product_code\"] == code,nullValue_cols ].isnull().sum().sum()\n",
        "        model1 = KNNImputer(n_neighbors=5)\n",
        "        data.loc[data.product_code==code, feature] = model1.fit_transform(data.loc[data.product_code==code, feature])\n",
        "\n",
        "    data['measurement_avg'] = data[[f'measurement_{i}' for i in range(3, 17)]].mean(axis=1)\n",
        "    data['measurement_std'] = data[[f'measurement_{i}' for i in range(3, 17)]].std(axis=1)\n",
        "    data['measurement_median'] = data[[f'measurement_{i}' for i in range(3, 17)]].median(axis=1)\n",
        "    data['measurement_max'] = data[[f'measurement_{i}' for i in range(3, 17)]].max(axis=1)\n",
        "    data['measurement_min'] = data[[f'measurement_{i}' for i in range(3, 17)]].min(axis=1)\n",
        "    data['measurement_skew'] = data[[f'measurement_{i}' for i in range(3, 17)]].skew(axis=1)\n",
        "    \n",
        "    df_train = data.iloc[:df_train.shape[0],:]\n",
        "    df_test = data.iloc[df_train.shape[0]:,:]\n",
        "\n",
        "    woe_encoder = WoEEncoder(variables=['attribute_0'])\n",
        "    woe_encoder.fit(df_train, df_train['failure'])\n",
        "    df_train = woe_encoder.transform(df_train)\n",
        "    df_test = woe_encoder.transform(df_test)\n",
        "\n",
        "    df_train = df_train.drop(columns=['measurement_std', 'measurement_median', 'measurement_max', 'measurement_min', 'measurement_skew'])\n",
        "    df_test = df_test.drop(columns=['measurement_std', 'measurement_median', 'measurement_max', 'measurement_min', 'measurement_skew'])\n",
        "\n",
        "    return df_train, df_test"
      ],
      "metadata": {
        "id": "iUGbPj5ujZrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train, df_test = preprocessing(train, test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XgoXUiigkKvH",
        "outputId": "2dc72e3e-9862-4743-9fa8-47dd70d18505"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns selected by correlation sum of the 3 first rows : \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  Selected columns  correlation total\n",
              "0    measurement_8              0.454\n",
              "1   measurement_11              0.395\n",
              "2    measurement_5              0.386\n",
              "3    measurement_6              0.365\n",
              "4    measurement_7              0.336\n",
              "5    measurement_4              0.331\n",
              "6   measurement_15              0.301\n",
              "7   measurement_10              0.300\n",
              "8   measurement_16              0.252\n",
              "9   measurement_14              0.225"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-447ee5b8-2aec-47eb-9730-7c1511420e49\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Selected columns</th>\n",
              "      <th>correlation total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>measurement_8</td>\n",
              "      <td>0.454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>measurement_11</td>\n",
              "      <td>0.395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>measurement_5</td>\n",
              "      <td>0.386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>measurement_6</td>\n",
              "      <td>0.365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>measurement_7</td>\n",
              "      <td>0.336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>measurement_4</td>\n",
              "      <td>0.331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>measurement_15</td>\n",
              "      <td>0.301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>measurement_10</td>\n",
              "      <td>0.300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>measurement_16</td>\n",
              "      <td>0.252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>measurement_14</td>\n",
              "      <td>0.225</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-447ee5b8-2aec-47eb-9730-7c1511420e49')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-447ee5b8-2aec-47eb-9730-7c1511420e49 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-447ee5b8-2aec-47eb-9730-7c1511420e49');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-------- Product code A ----------\n",
            "\n",
            "filled by linear model :\n",
            "measurement_17 : 386\n",
            "measurement_8 : 167\n",
            "measurement_11 : 225\n",
            "measurement_5 : 113\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "measurement_6 : 146\n",
            "measurement_7 : 153\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "measurement_4 : 79\n",
            "measurement_15 : 273\n",
            "measurement_10 : 209\n",
            "measurement_16 : 293\n",
            "measurement_14 : 237\n",
            "\n",
            "2281 filled by linear model \n",
            "1568 filled by KNN \n",
            "\n",
            "-------- Product code B ----------\n",
            "\n",
            "filled by linear model :\n",
            "measurement_17 : 418\n",
            "measurement_8 : 165\n",
            "measurement_11 : 220\n",
            "measurement_5 : 83\n",
            "measurement_6 : 106\n",
            "measurement_7 : 176\n",
            "measurement_4 : 80\n",
            "measurement_15 : 294\n",
            "measurement_10 : 197\n",
            "measurement_16 : 358\n",
            "measurement_14 : 330\n",
            "\n",
            "2427 filled by linear model \n",
            "1548 filled by KNN \n",
            "\n",
            "-------- Product code C ----------\n",
            "\n",
            "filled by linear model :\n",
            "measurement_17 : 391\n",
            "measurement_8 : 211\n",
            "measurement_11 : 231\n",
            "measurement_5 : 141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "measurement_6 : 150\n",
            "measurement_7 : 140\n",
            "measurement_4 : 110\n",
            "measurement_15 : 319\n",
            "measurement_10 : 262\n",
            "measurement_16 : 343\n",
            "measurement_14 : 340\n",
            "\n",
            "2638 filled by linear model \n",
            "1706 filled by KNN \n",
            "\n",
            "-------- Product code D ----------\n",
            "\n",
            "filled by linear model :\n",
            "measurement_17 : 398\n",
            "measurement_8 : 146\n",
            "measurement_11 : 265\n",
            "measurement_5 : 87\n",
            "measurement_6 : 118\n",
            "measurement_7 : 146\n",
            "measurement_4 : 88\n",
            "measurement_15 : 313\n",
            "measurement_10 : 174\n",
            "measurement_16 : 322\n",
            "measurement_14 : 316\n",
            "\n",
            "2373 filled by linear model \n",
            "1600 filled by KNN \n",
            "\n",
            "-------- Product code E ----------\n",
            "\n",
            "filled by linear model :\n",
            "measurement_17 : 429\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "measurement_8 : 171\n",
            "measurement_11 : 244\n",
            "measurement_5 : 116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "measurement_6 : 127\n",
            "measurement_7 : 185\n",
            "measurement_4 : 105\n",
            "measurement_15 : 315\n",
            "measurement_10 : 193\n",
            "measurement_16 : 316\n",
            "measurement_14 : 297\n",
            "\n",
            "2498 filled by linear model \n",
            "1634 filled by KNN \n",
            "\n",
            "-------- Product code F ----------\n",
            "\n",
            "filled by linear model :\n",
            "measurement_17 : 420\n",
            "measurement_8 : 194\n",
            "measurement_11 : 226\n",
            "measurement_5 : 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "measurement_6 : 137\n",
            "measurement_7 : 147\n",
            "measurement_4 : 91\n",
            "measurement_15 : 333\n",
            "measurement_10 : 186\n",
            "measurement_16 : 356\n",
            "measurement_14 : 348\n",
            "\n",
            "2528 filled by linear model \n",
            "1545 filled by KNN \n",
            "\n",
            "-------- Product code G ----------\n",
            "\n",
            "filled by linear model :\n",
            "measurement_17 : 373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "measurement_8 : 188\n",
            "measurement_11 : 221\n",
            "measurement_5 : 104\n",
            "measurement_6 : 146\n",
            "measurement_7 : 145\n",
            "measurement_4 : 93\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "measurement_15 : 299\n",
            "measurement_10 : 226\n",
            "measurement_16 : 343\n",
            "measurement_14 : 268\n",
            "\n",
            "2406 filled by linear model \n",
            "1518 filled by KNN \n",
            "\n",
            "-------- Product code H ----------\n",
            "\n",
            "filled by linear model :\n",
            "measurement_17 : 361\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "measurement_8 : 147\n",
            "measurement_11 : 205\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "measurement_5 : 112\n",
            "measurement_6 : 121\n",
            "measurement_7 : 158\n",
            "measurement_4 : 75\n",
            "measurement_15 : 299\n",
            "measurement_10 : 217\n",
            "measurement_16 : 340\n",
            "measurement_14 : 283\n",
            "\n",
            "2318 filled by linear model \n",
            "1565 filled by KNN \n",
            "\n",
            "-------- Product code I ----------\n",
            "\n",
            "filled by linear model :\n",
            "measurement_17 : 377\n",
            "measurement_8 : 192\n",
            "measurement_11 : 209\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "measurement_5 : 119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "measurement_6 : 132\n",
            "measurement_7 : 136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_huber.py:332: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "measurement_4 : 89\n",
            "measurement_15 : 350\n",
            "measurement_10 : 246\n",
            "measurement_16 : 294\n",
            "measurement_14 : 283\n",
            "\n",
            "2427 filled by linear model \n",
            "1402 filled by KNN \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = ['loading', 'attribute_0', 'measurement_17', 'measurement_0', 'measurement_1', 'measurement_2', 'area', 'm3_missing', 'm5_missing', 'measurement_avg']"
      ],
      "metadata": {
        "id": "JCWplx0vlNrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_FEATURE = len(features)\n",
        "DROPOUT_RATE = 0.2"
      ],
      "metadata": {
        "id": "rrXafrksdak4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# [ref] https://www.kaggle.com/competitions/tabular-playground-series-aug-2022/discussion/349385\n",
        "def get_stacked_dense(x, cur_dim, stack_depth, activation):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "        `x`: current layer\n",
        "        `cur_dim`: the number of dimensions of the first stacked layer\n",
        "        `stack_depth`: the number of stacked layers\n",
        "        `activation`: the activation function used for the dense layers\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "        `x`: the output of the stacked layers\n",
        "    \"\"\"\n",
        "    for i in range(stack_depth):\n",
        "        x = Dense(cur_dim-i, activation)(x)\n",
        "    return x\n",
        "\n",
        "def get_triple_stacked(x_0, start_dim):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "        `x_0`: current layer\n",
        "        `start_dim`: the number of dimensions of the first stacked layer\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "        `x_00000, x_00001, x_00010, x_00011, x_00100, x_00101, x_00110, x_00111`: the outputs of the stacked layers\n",
        "    \"\"\"\n",
        "    x_00 = Dense(start_dim, swish)(x_0)\n",
        "    x_000 = Dense(start_dim-1, swish)(x_00)\n",
        "    x_0000 = Dense(start_dim-2, swish)(x_000)\n",
        "\n",
        "    x_00000 = get_stacked_dense(x_0000, start_dim-3, 2, swish)\n",
        "    x_00000 = BatchNormalization()(x_00000)\n",
        "\n",
        "    x_00001 = get_stacked_dense(x_0000, start_dim-4, 2, swish)\n",
        "    x_00001 = BatchNormalization()(x_00001)\n",
        "\n",
        "    x_0001 = Dense(start_dim-3, swish)(x_000)\n",
        "    x_00010 = get_stacked_dense(x_0001, start_dim-4, 2, swish)\n",
        "    x_00010 = BatchNormalization()(x_00010)\n",
        "\n",
        "    x_00011 = get_stacked_dense(x_0001, start_dim-5, 2, swish)\n",
        "    x_00011 = BatchNormalization()(x_00011)\n",
        "\n",
        "    x_001 = Dense(start_dim-2, swish)(x_00)\n",
        "    x_0010 = Dense(start_dim-3, swish)(x_001)\n",
        "    x_00100 = get_stacked_dense(x_0010, start_dim-4, 2, swish)\n",
        "    x_00100 = BatchNormalization()(x_00100)\n",
        "\n",
        "    x_00101 = get_stacked_dense(x_0010, start_dim-5, 2, swish)\n",
        "    x_00101 = BatchNormalization()(x_00101)\n",
        "\n",
        "    x_0011 = Dense(start_dim-4, swish)(x_001)\n",
        "    x_00110 = get_stacked_dense(x_0011, start_dim-5, 2, swish)\n",
        "    x_00110 = BatchNormalization()(x_00110)\n",
        "\n",
        "    x_00111 = get_stacked_dense(x_0011, start_dim-6, 2, swish)\n",
        "    x_00111 = BatchNormalization()(x_00111)\n",
        "\n",
        "    return x_00000, x_00001, x_00010, x_00011, x_00100, x_00101, x_00110, x_00111\n",
        "\n",
        "def get_model(feature_num):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "        `feature_num`: the number of the features from the training dataset\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "        `model`: the assembled model\n",
        "    \"\"\"\n",
        "    inputs = Input(shape=(feature_num,))\n",
        "    x = Dense(20, swish)(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(DROPOUT_RATE)(x)\n",
        "    x_0 = Dense(20, swish)(x)\n",
        "    x_00000, x_00001, x_00010, x_00011, x_00100, x_00101, x_00110, x_00111 = get_triple_stacked(x_0, 19)\n",
        "    x_01000, x_01001, x_01010, x_01011, x_01100, x_01101, x_10110, x_01111 = get_triple_stacked(x_0, 18)\n",
        "    cat_layer_list = [x_00000, x_00001, x_00010, x_00011, x_00100, x_00101, x_00110, x_00111, x_01000, x_01001, x_01010, x_01011, x_01100, x_01101, x_10110, x_01111]\n",
        "    cat = concatenate(cat_layer_list)\n",
        "    dense1 = Dense(20, swish)(cat)\n",
        "    output = Dense(1, sigmoid)(dense1)\n",
        "    model = Model(inputs, output)\n",
        "    return model"
      ],
      "metadata": {
        "id": "lmz6e_Lhe3Sy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ES = tf.keras.callbacks.EarlyStopping(\n",
        "            monitor=\"val_loss\", patience=12, mode=\"min\", restore_best_weights=True, verbose=2)\n",
        "LR = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "            monitor=\"val_loss\", factor=0.5, patience=5, mode=\"min\", restore_best_weights=True, min_lr=1e-12, verbose=2)"
      ],
      "metadata": {
        "id": "PfP9TvNwrgfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = np.zeros((df_test.shape[0], 1))\n",
        "total_folds = len(folds_dict.keys())\n",
        "for i, fold in enumerate(folds_dict.keys()):\n",
        "    \n",
        "    print(fold)\n",
        "    \n",
        "    x_train, y_train = df_train[df_train['product_code'].isin(folds_dict[fold][0])][features].values, df_train[df_train['product_code'].isin(folds_dict[fold][0])]['failure'].values\n",
        "    x_val, y_val = df_train[df_train['product_code'].isin(folds_dict[fold][1])][features].values, df_train[df_train['product_code'].isin(folds_dict[fold][1])]['failure'].values\n",
        "\n",
        "    model = get_model(NUM_FEATURE)\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-2), loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
        "    history = model.fit(x_train, y_train,\n",
        "                        batch_size=32,\n",
        "                        epochs=300,\n",
        "                        validation_data=(x_val, y_val),\n",
        "                        callbacks=[ES, LR],\n",
        "                        verbose=1)\n",
        "    history_df = pd.DataFrame(history.history)\n",
        "    print(f\"Min val loss: {min(history_df['val_loss'].values)}\")\n",
        "    model.save(f\"model{i}.h5\")\n",
        "    y_pred = model.predict(df_test[features].values)\n",
        "    test_predictions += y_pred / total_folds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lf1zTGgjt462",
        "outputId": "9af73b04-4dc1-42c3-99b7-2a935301fdd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1\n",
            "Epoch 1/300\n",
            "507/507 [==============================] - 18s 17ms/step - loss: 0.5238 - binary_accuracy: 0.7846 - val_loss: 0.5168 - val_binary_accuracy: 0.7864 - lr: 0.0100\n",
            "Epoch 2/300\n",
            "507/507 [==============================] - 8s 16ms/step - loss: 0.5117 - binary_accuracy: 0.7879 - val_loss: 0.5158 - val_binary_accuracy: 0.7864 - lr: 0.0100\n",
            "Epoch 3/300\n",
            "507/507 [==============================] - 8s 15ms/step - loss: 0.5112 - binary_accuracy: 0.7880 - val_loss: 0.5107 - val_binary_accuracy: 0.7864 - lr: 0.0100\n",
            "Epoch 4/300\n",
            "507/507 [==============================] - 7s 14ms/step - loss: 0.5118 - binary_accuracy: 0.7880 - val_loss: 0.5123 - val_binary_accuracy: 0.7864 - lr: 0.0100\n",
            "Epoch 5/300\n",
            "507/507 [==============================] - 7s 14ms/step - loss: 0.5120 - binary_accuracy: 0.7880 - val_loss: 0.5114 - val_binary_accuracy: 0.7864 - lr: 0.0100\n",
            "Epoch 6/300\n",
            "507/507 [==============================] - 8s 15ms/step - loss: 0.5113 - binary_accuracy: 0.7880 - val_loss: 0.5209 - val_binary_accuracy: 0.7864 - lr: 0.0100\n",
            "Epoch 7/300\n",
            "507/507 [==============================] - 9s 18ms/step - loss: 0.5109 - binary_accuracy: 0.7880 - val_loss: 0.5282 - val_binary_accuracy: 0.7864 - lr: 0.0100\n",
            "Epoch 8/300\n",
            "507/507 [==============================] - ETA: 0s - loss: 0.5109 - binary_accuracy: 0.7877\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "507/507 [==============================] - 8s 15ms/step - loss: 0.5109 - binary_accuracy: 0.7877 - val_loss: 0.5204 - val_binary_accuracy: 0.7864 - lr: 0.0100\n",
            "Epoch 9/300\n",
            "507/507 [==============================] - 7s 14ms/step - loss: 0.5102 - binary_accuracy: 0.7880 - val_loss: 0.5107 - val_binary_accuracy: 0.7864 - lr: 0.0050\n",
            "Epoch 10/300\n",
            "507/507 [==============================] - 7s 15ms/step - loss: 0.5102 - binary_accuracy: 0.7880 - val_loss: 0.5111 - val_binary_accuracy: 0.7864 - lr: 0.0050\n",
            "Epoch 11/300\n",
            "507/507 [==============================] - 7s 15ms/step - loss: 0.5100 - binary_accuracy: 0.7880 - val_loss: 0.5114 - val_binary_accuracy: 0.7864 - lr: 0.0050\n",
            "Epoch 12/300\n",
            "507/507 [==============================] - 8s 15ms/step - loss: 0.5096 - binary_accuracy: 0.7882 - val_loss: 0.5112 - val_binary_accuracy: 0.7864 - lr: 0.0050\n",
            "Epoch 13/300\n",
            "504/507 [============================>.] - ETA: 0s - loss: 0.5096 - binary_accuracy: 0.7881\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "507/507 [==============================] - 7s 14ms/step - loss: 0.5098 - binary_accuracy: 0.7880 - val_loss: 0.5113 - val_binary_accuracy: 0.7864 - lr: 0.0050\n",
            "Epoch 14/300\n",
            "507/507 [==============================] - 8s 15ms/step - loss: 0.5099 - binary_accuracy: 0.7880 - val_loss: 0.5103 - val_binary_accuracy: 0.7864 - lr: 0.0025\n",
            "Epoch 15/300\n",
            "507/507 [==============================] - 7s 14ms/step - loss: 0.5090 - binary_accuracy: 0.7880 - val_loss: 0.5105 - val_binary_accuracy: 0.7864 - lr: 0.0025\n",
            "Epoch 16/300\n",
            "507/507 [==============================] - 7s 15ms/step - loss: 0.5091 - binary_accuracy: 0.7880 - val_loss: 0.5102 - val_binary_accuracy: 0.7864 - lr: 0.0025\n",
            "Epoch 17/300\n",
            "507/507 [==============================] - 7s 13ms/step - loss: 0.5095 - binary_accuracy: 0.7880 - val_loss: 0.5109 - val_binary_accuracy: 0.7864 - lr: 0.0025\n",
            "Epoch 18/300\n",
            "507/507 [==============================] - 7s 14ms/step - loss: 0.5096 - binary_accuracy: 0.7880 - val_loss: 0.5105 - val_binary_accuracy: 0.7864 - lr: 0.0025\n",
            "Epoch 19/300\n",
            "507/507 [==============================] - 7s 14ms/step - loss: 0.5093 - binary_accuracy: 0.7880 - val_loss: 0.5103 - val_binary_accuracy: 0.7864 - lr: 0.0025\n",
            "Epoch 20/300\n",
            "507/507 [==============================] - 7s 14ms/step - loss: 0.5093 - binary_accuracy: 0.7880 - val_loss: 0.5102 - val_binary_accuracy: 0.7864 - lr: 0.0025\n",
            "Epoch 21/300\n",
            "506/507 [============================>.] - ETA: 0s - loss: 0.5089 - binary_accuracy: 0.7879\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "507/507 [==============================] - 7s 13ms/step - loss: 0.5088 - binary_accuracy: 0.7880 - val_loss: 0.5103 - val_binary_accuracy: 0.7864 - lr: 0.0025\n",
            "Epoch 22/300\n",
            "507/507 [==============================] - 7s 14ms/step - loss: 0.5092 - binary_accuracy: 0.7880 - val_loss: 0.5102 - val_binary_accuracy: 0.7864 - lr: 0.0012\n",
            "Epoch 23/300\n",
            "507/507 [==============================] - 7s 13ms/step - loss: 0.5087 - binary_accuracy: 0.7880 - val_loss: 0.5106 - val_binary_accuracy: 0.7864 - lr: 0.0012\n",
            "Epoch 24/300\n",
            "507/507 [==============================] - 7s 13ms/step - loss: 0.5091 - binary_accuracy: 0.7880 - val_loss: 0.5100 - val_binary_accuracy: 0.7864 - lr: 0.0012\n",
            "Epoch 25/300\n",
            "507/507 [==============================] - 9s 17ms/step - loss: 0.5088 - binary_accuracy: 0.7880 - val_loss: 0.5103 - val_binary_accuracy: 0.7864 - lr: 0.0012\n",
            "Epoch 26/300\n",
            "507/507 [==============================] - 7s 14ms/step - loss: 0.5086 - binary_accuracy: 0.7880 - val_loss: 0.5104 - val_binary_accuracy: 0.7864 - lr: 0.0012\n",
            "Epoch 27/300\n",
            "507/507 [==============================] - 7s 13ms/step - loss: 0.5093 - binary_accuracy: 0.7880 - val_loss: 0.5102 - val_binary_accuracy: 0.7864 - lr: 0.0012\n",
            "Epoch 28/300\n",
            "507/507 [==============================] - 7s 13ms/step - loss: 0.5090 - binary_accuracy: 0.7880 - val_loss: 0.5103 - val_binary_accuracy: 0.7864 - lr: 0.0012\n",
            "Epoch 29/300\n",
            "506/507 [============================>.] - ETA: 0s - loss: 0.5095 - binary_accuracy: 0.7879\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "507/507 [==============================] - 7s 14ms/step - loss: 0.5092 - binary_accuracy: 0.7880 - val_loss: 0.5101 - val_binary_accuracy: 0.7864 - lr: 0.0012\n",
            "Epoch 30/300\n",
            "507/507 [==============================] - 7s 13ms/step - loss: 0.5086 - binary_accuracy: 0.7880 - val_loss: 0.5099 - val_binary_accuracy: 0.7864 - lr: 6.2500e-04\n",
            "Epoch 31/300\n",
            "507/507 [==============================] - 6s 12ms/step - loss: 0.5091 - binary_accuracy: 0.7880 - val_loss: 0.5102 - val_binary_accuracy: 0.7864 - lr: 6.2500e-04\n",
            "Epoch 32/300\n",
            "507/507 [==============================] - 7s 13ms/step - loss: 0.5084 - binary_accuracy: 0.7880 - val_loss: 0.5101 - val_binary_accuracy: 0.7864 - lr: 6.2500e-04\n",
            "Epoch 33/300\n",
            "507/507 [==============================] - 7s 13ms/step - loss: 0.5088 - binary_accuracy: 0.7879 - val_loss: 0.5103 - val_binary_accuracy: 0.7864 - lr: 6.2500e-04\n",
            "Epoch 34/300\n",
            "507/507 [==============================] - 8s 16ms/step - loss: 0.5089 - binary_accuracy: 0.7880 - val_loss: 0.5101 - val_binary_accuracy: 0.7864 - lr: 6.2500e-04\n",
            "Epoch 35/300\n",
            "505/507 [============================>.] - ETA: 0s - loss: 0.5089 - binary_accuracy: 0.7881\n",
            "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
            "507/507 [==============================] - 11s 22ms/step - loss: 0.5090 - binary_accuracy: 0.7880 - val_loss: 0.5101 - val_binary_accuracy: 0.7864 - lr: 6.2500e-04\n",
            "Epoch 36/300\n",
            "507/507 [==============================] - 7s 13ms/step - loss: 0.5084 - binary_accuracy: 0.7880 - val_loss: 0.5099 - val_binary_accuracy: 0.7864 - lr: 3.1250e-04\n",
            "Epoch 37/300\n",
            "507/507 [==============================] - 7s 13ms/step - loss: 0.5085 - binary_accuracy: 0.7880 - val_loss: 0.5100 - val_binary_accuracy: 0.7864 - lr: 3.1250e-04\n",
            "Epoch 38/300\n",
            "507/507 [==============================] - 7s 13ms/step - loss: 0.5091 - binary_accuracy: 0.7880 - val_loss: 0.5101 - val_binary_accuracy: 0.7864 - lr: 3.1250e-04\n",
            "Epoch 39/300\n",
            "507/507 [==============================] - 7s 13ms/step - loss: 0.5089 - binary_accuracy: 0.7880 - val_loss: 0.5100 - val_binary_accuracy: 0.7864 - lr: 3.1250e-04\n",
            "Epoch 40/300\n",
            "505/507 [============================>.] - ETA: 0s - loss: 0.5091 - binary_accuracy: 0.7877\n",
            "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
            "507/507 [==============================] - 7s 13ms/step - loss: 0.5087 - binary_accuracy: 0.7880 - val_loss: 0.5099 - val_binary_accuracy: 0.7864 - lr: 3.1250e-04\n",
            "Epoch 41/300\n",
            "507/507 [==============================] - 7s 14ms/step - loss: 0.5085 - binary_accuracy: 0.7880 - val_loss: 0.5099 - val_binary_accuracy: 0.7864 - lr: 1.5625e-04\n",
            "Epoch 42/300\n",
            "507/507 [==============================] - 7s 13ms/step - loss: 0.5083 - binary_accuracy: 0.7880 - val_loss: 0.5099 - val_binary_accuracy: 0.7864 - lr: 1.5625e-04\n",
            "Epoch 43/300\n",
            "507/507 [==============================] - 7s 14ms/step - loss: 0.5078 - binary_accuracy: 0.7880 - val_loss: 0.5099 - val_binary_accuracy: 0.7864 - lr: 1.5625e-04\n",
            "Epoch 44/300\n",
            "507/507 [==============================] - 7s 14ms/step - loss: 0.5089 - binary_accuracy: 0.7880 - val_loss: 0.5099 - val_binary_accuracy: 0.7864 - lr: 1.5625e-04\n",
            "Epoch 45/300\n",
            "505/507 [============================>.] - ETA: 0s - loss: 0.5085 - binary_accuracy: 0.7879\n",
            "Epoch 45: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
            "507/507 [==============================] - 6s 13ms/step - loss: 0.5082 - binary_accuracy: 0.7880 - val_loss: 0.5099 - val_binary_accuracy: 0.7864 - lr: 1.5625e-04\n",
            "Epoch 46/300\n",
            "507/507 [==============================] - 7s 13ms/step - loss: 0.5086 - binary_accuracy: 0.7880 - val_loss: 0.5100 - val_binary_accuracy: 0.7864 - lr: 7.8125e-05\n",
            "Epoch 47/300\n",
            "507/507 [==============================] - 7s 14ms/step - loss: 0.5084 - binary_accuracy: 0.7880 - val_loss: 0.5099 - val_binary_accuracy: 0.7864 - lr: 7.8125e-05\n",
            "Epoch 48/300\n",
            "505/507 [============================>.] - ETA: 0s - loss: 0.5081 - binary_accuracy: 0.7882Restoring model weights from the end of the best epoch: 36.\n",
            "507/507 [==============================] - 7s 14ms/step - loss: 0.5083 - binary_accuracy: 0.7880 - val_loss: 0.5099 - val_binary_accuracy: 0.7864 - lr: 7.8125e-05\n",
            "Epoch 48: early stopping\n",
            "Min val loss: 0.509900689125061\n",
            "650/650 [==============================] - 3s 3ms/step\n",
            "Fold 2\n",
            "Epoch 1/300\n",
            "491/491 [==============================] - 16s 16ms/step - loss: 0.5162 - binary_accuracy: 0.7888 - val_loss: 0.5244 - val_binary_accuracy: 0.7810 - lr: 0.0100\n",
            "Epoch 2/300\n",
            "491/491 [==============================] - 7s 15ms/step - loss: 0.5073 - binary_accuracy: 0.7918 - val_loss: 0.5196 - val_binary_accuracy: 0.7810 - lr: 0.0100\n",
            "Epoch 3/300\n",
            "491/491 [==============================] - 8s 15ms/step - loss: 0.5073 - binary_accuracy: 0.7917 - val_loss: 0.5271 - val_binary_accuracy: 0.7810 - lr: 0.0100\n",
            "Epoch 4/300\n",
            "491/491 [==============================] - 8s 16ms/step - loss: 0.5071 - binary_accuracy: 0.7918 - val_loss: 0.5263 - val_binary_accuracy: 0.7810 - lr: 0.0100\n",
            "Epoch 5/300\n",
            "491/491 [==============================] - 8s 16ms/step - loss: 0.5067 - binary_accuracy: 0.7917 - val_loss: 0.5222 - val_binary_accuracy: 0.7810 - lr: 0.0100\n",
            "Epoch 6/300\n",
            "491/491 [==============================] - 8s 16ms/step - loss: 0.5061 - binary_accuracy: 0.7918 - val_loss: 0.5287 - val_binary_accuracy: 0.7810 - lr: 0.0100\n",
            "Epoch 7/300\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.5063 - binary_accuracy: 0.7917\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "491/491 [==============================] - 7s 14ms/step - loss: 0.5063 - binary_accuracy: 0.7917 - val_loss: 0.5207 - val_binary_accuracy: 0.7810 - lr: 0.0100\n",
            "Epoch 8/300\n",
            "491/491 [==============================] - 7s 14ms/step - loss: 0.5049 - binary_accuracy: 0.7915 - val_loss: 0.5217 - val_binary_accuracy: 0.7810 - lr: 0.0050\n",
            "Epoch 9/300\n",
            "491/491 [==============================] - 7s 13ms/step - loss: 0.5052 - binary_accuracy: 0.7918 - val_loss: 0.5181 - val_binary_accuracy: 0.7810 - lr: 0.0050\n",
            "Epoch 10/300\n",
            "491/491 [==============================] - 7s 15ms/step - loss: 0.5045 - binary_accuracy: 0.7918 - val_loss: 0.5175 - val_binary_accuracy: 0.7810 - lr: 0.0050\n",
            "Epoch 11/300\n",
            "491/491 [==============================] - 8s 15ms/step - loss: 0.5046 - binary_accuracy: 0.7918 - val_loss: 0.5175 - val_binary_accuracy: 0.7810 - lr: 0.0050\n",
            "Epoch 12/300\n",
            "491/491 [==============================] - 7s 15ms/step - loss: 0.5042 - binary_accuracy: 0.7918 - val_loss: 0.5219 - val_binary_accuracy: 0.7810 - lr: 0.0050\n",
            "Epoch 13/300\n",
            "491/491 [==============================] - 8s 16ms/step - loss: 0.5038 - binary_accuracy: 0.7917 - val_loss: 0.5198 - val_binary_accuracy: 0.7810 - lr: 0.0050\n",
            "Epoch 14/300\n",
            "491/491 [==============================] - 8s 17ms/step - loss: 0.5048 - binary_accuracy: 0.7918 - val_loss: 0.5177 - val_binary_accuracy: 0.7810 - lr: 0.0050\n",
            "Epoch 15/300\n",
            "491/491 [==============================] - ETA: 0s - loss: 0.5053 - binary_accuracy: 0.7917\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "491/491 [==============================] - 8s 16ms/step - loss: 0.5053 - binary_accuracy: 0.7917 - val_loss: 0.5202 - val_binary_accuracy: 0.7810 - lr: 0.0050\n",
            "Epoch 16/300\n",
            "491/491 [==============================] - 8s 16ms/step - loss: 0.5041 - binary_accuracy: 0.7918 - val_loss: 0.5180 - val_binary_accuracy: 0.7810 - lr: 0.0025\n",
            "Epoch 17/300\n",
            "491/491 [==============================] - 8s 17ms/step - loss: 0.5038 - binary_accuracy: 0.7918 - val_loss: 0.5177 - val_binary_accuracy: 0.7810 - lr: 0.0025\n",
            "Epoch 18/300\n",
            "491/491 [==============================] - 8s 16ms/step - loss: 0.5040 - binary_accuracy: 0.7918 - val_loss: 0.5180 - val_binary_accuracy: 0.7810 - lr: 0.0025\n",
            "Epoch 19/300\n",
            "491/491 [==============================] - 8s 17ms/step - loss: 0.5040 - binary_accuracy: 0.7918 - val_loss: 0.5188 - val_binary_accuracy: 0.7810 - lr: 0.0025\n",
            "Epoch 20/300\n",
            "488/491 [============================>.] - ETA: 0s - loss: 0.5042 - binary_accuracy: 0.7914\n",
            "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "491/491 [==============================] - 8s 17ms/step - loss: 0.5038 - binary_accuracy: 0.7918 - val_loss: 0.5184 - val_binary_accuracy: 0.7810 - lr: 0.0025\n",
            "Epoch 21/300\n",
            "491/491 [==============================] - 8s 16ms/step - loss: 0.5037 - binary_accuracy: 0.7918 - val_loss: 0.5177 - val_binary_accuracy: 0.7810 - lr: 0.0012\n",
            "Epoch 22/300\n",
            "491/491 [==============================] - 8s 16ms/step - loss: 0.5037 - binary_accuracy: 0.7918 - val_loss: 0.5180 - val_binary_accuracy: 0.7810 - lr: 0.0012\n",
            "Epoch 23/300\n",
            "489/491 [============================>.] - ETA: 0s - loss: 0.5035 - binary_accuracy: 0.7919Restoring model weights from the end of the best epoch: 11.\n",
            "491/491 [==============================] - 9s 18ms/step - loss: 0.5036 - binary_accuracy: 0.7918 - val_loss: 0.5179 - val_binary_accuracy: 0.7810 - lr: 0.0012\n",
            "Epoch 23: early stopping\n",
            "Min val loss: 0.5174936652183533\n",
            "650/650 [==============================] - 4s 4ms/step\n",
            "Fold 3\n",
            "Epoch 1/300\n",
            "512/512 [==============================] - 20s 21ms/step - loss: 0.5149 - binary_accuracy: 0.7909 - val_loss: 0.5260 - val_binary_accuracy: 0.7776 - lr: 0.0100\n",
            "Epoch 2/300\n",
            "512/512 [==============================] - 8s 15ms/step - loss: 0.5062 - binary_accuracy: 0.7934 - val_loss: 0.5290 - val_binary_accuracy: 0.7776 - lr: 0.0100\n",
            "Epoch 3/300\n",
            "512/512 [==============================] - 8s 15ms/step - loss: 0.5044 - binary_accuracy: 0.7935 - val_loss: 0.5217 - val_binary_accuracy: 0.7776 - lr: 0.0100\n",
            "Epoch 4/300\n",
            "512/512 [==============================] - 8s 15ms/step - loss: 0.5050 - binary_accuracy: 0.7934 - val_loss: 0.5209 - val_binary_accuracy: 0.7776 - lr: 0.0100\n",
            "Epoch 5/300\n",
            "512/512 [==============================] - 8s 15ms/step - loss: 0.5043 - binary_accuracy: 0.7935 - val_loss: 0.5421 - val_binary_accuracy: 0.7776 - lr: 0.0100\n",
            "Epoch 6/300\n",
            "512/512 [==============================] - 8s 16ms/step - loss: 0.5049 - binary_accuracy: 0.7933 - val_loss: 0.5212 - val_binary_accuracy: 0.7776 - lr: 0.0100\n",
            "Epoch 7/300\n",
            "512/512 [==============================] - 8s 15ms/step - loss: 0.5045 - binary_accuracy: 0.7934 - val_loss: 0.5216 - val_binary_accuracy: 0.7776 - lr: 0.0100\n",
            "Epoch 8/300\n",
            "512/512 [==============================] - 8s 15ms/step - loss: 0.5035 - binary_accuracy: 0.7935 - val_loss: 0.5283 - val_binary_accuracy: 0.7776 - lr: 0.0100\n",
            "Epoch 9/300\n",
            "511/512 [============================>.] - ETA: 0s - loss: 0.5042 - binary_accuracy: 0.7935\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "512/512 [==============================] - 8s 15ms/step - loss: 0.5042 - binary_accuracy: 0.7935 - val_loss: 0.5215 - val_binary_accuracy: 0.7776 - lr: 0.0100\n",
            "Epoch 10/300\n",
            "512/512 [==============================] - 7s 14ms/step - loss: 0.5024 - binary_accuracy: 0.7935 - val_loss: 0.5216 - val_binary_accuracy: 0.7776 - lr: 0.0050\n",
            "Epoch 11/300\n",
            "512/512 [==============================] - 8s 15ms/step - loss: 0.5036 - binary_accuracy: 0.7935 - val_loss: 0.5211 - val_binary_accuracy: 0.7776 - lr: 0.0050\n",
            "Epoch 12/300\n",
            "512/512 [==============================] - 7s 15ms/step - loss: 0.5020 - binary_accuracy: 0.7935 - val_loss: 0.5238 - val_binary_accuracy: 0.7776 - lr: 0.0050\n",
            "Epoch 13/300\n",
            "512/512 [==============================] - 8s 15ms/step - loss: 0.5031 - binary_accuracy: 0.7935 - val_loss: 0.5213 - val_binary_accuracy: 0.7776 - lr: 0.0050\n",
            "Epoch 14/300\n",
            "509/512 [============================>.] - ETA: 0s - loss: 0.5029 - binary_accuracy: 0.7935\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "512/512 [==============================] - 8s 15ms/step - loss: 0.5030 - binary_accuracy: 0.7935 - val_loss: 0.5507 - val_binary_accuracy: 0.7776 - lr: 0.0050\n",
            "Epoch 15/300\n",
            "512/512 [==============================] - 8s 15ms/step - loss: 0.5025 - binary_accuracy: 0.7935 - val_loss: 0.5236 - val_binary_accuracy: 0.7772 - lr: 0.0025\n",
            "Epoch 16/300\n",
            "511/512 [============================>.] - ETA: 0s - loss: 0.5022 - binary_accuracy: 0.7935Restoring model weights from the end of the best epoch: 4.\n",
            "512/512 [==============================] - 8s 15ms/step - loss: 0.5022 - binary_accuracy: 0.7935 - val_loss: 0.5278 - val_binary_accuracy: 0.7772 - lr: 0.0025\n",
            "Epoch 16: early stopping\n",
            "Min val loss: 0.5208759903907776\n",
            "650/650 [==============================] - 4s 4ms/step\n",
            "Fold 4\n",
            "Epoch 1/300\n",
            "504/504 [==============================] - 19s 21ms/step - loss: 0.5186 - binary_accuracy: 0.7886 - val_loss: 0.5219 - val_binary_accuracy: 0.7831 - lr: 0.0100\n",
            "Epoch 2/300\n",
            "504/504 [==============================] - 8s 16ms/step - loss: 0.5094 - binary_accuracy: 0.7902 - val_loss: 0.5211 - val_binary_accuracy: 0.7831 - lr: 0.0100\n",
            "Epoch 3/300\n",
            "504/504 [==============================] - 8s 16ms/step - loss: 0.5086 - binary_accuracy: 0.7902 - val_loss: 0.5263 - val_binary_accuracy: 0.7830 - lr: 0.0100\n",
            "Epoch 4/300\n",
            "504/504 [==============================] - 8s 16ms/step - loss: 0.5085 - binary_accuracy: 0.7899 - val_loss: 0.5173 - val_binary_accuracy: 0.7831 - lr: 0.0100\n",
            "Epoch 5/300\n",
            "504/504 [==============================] - 8s 16ms/step - loss: 0.5075 - binary_accuracy: 0.7901 - val_loss: 0.5181 - val_binary_accuracy: 0.7831 - lr: 0.0100\n",
            "Epoch 6/300\n",
            "504/504 [==============================] - 8s 16ms/step - loss: 0.5076 - binary_accuracy: 0.7902 - val_loss: 0.7096 - val_binary_accuracy: 0.4563 - lr: 0.0100\n",
            "Epoch 7/300\n",
            "504/504 [==============================] - 9s 18ms/step - loss: 0.5076 - binary_accuracy: 0.7902 - val_loss: 0.6773 - val_binary_accuracy: 0.5715 - lr: 0.0100\n",
            "Epoch 8/300\n",
            "504/504 [==============================] - 8s 15ms/step - loss: 0.5091 - binary_accuracy: 0.7899 - val_loss: 0.5271 - val_binary_accuracy: 0.7831 - lr: 0.0100\n",
            "Epoch 9/300\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.5069 - binary_accuracy: 0.7902\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "504/504 [==============================] - 8s 16ms/step - loss: 0.5069 - binary_accuracy: 0.7902 - val_loss: 0.5181 - val_binary_accuracy: 0.7831 - lr: 0.0100\n",
            "Epoch 10/300\n",
            "504/504 [==============================] - 8s 16ms/step - loss: 0.5076 - binary_accuracy: 0.7902 - val_loss: 0.5176 - val_binary_accuracy: 0.7831 - lr: 0.0050\n",
            "Epoch 11/300\n",
            "504/504 [==============================] - 8s 16ms/step - loss: 0.5065 - binary_accuracy: 0.7902 - val_loss: 0.5168 - val_binary_accuracy: 0.7831 - lr: 0.0050\n",
            "Epoch 12/300\n",
            "504/504 [==============================] - 8s 16ms/step - loss: 0.5063 - binary_accuracy: 0.7902 - val_loss: 0.5162 - val_binary_accuracy: 0.7831 - lr: 0.0050\n",
            "Epoch 13/300\n",
            "504/504 [==============================] - 8s 16ms/step - loss: 0.5063 - binary_accuracy: 0.7902 - val_loss: 0.5175 - val_binary_accuracy: 0.7831 - lr: 0.0050\n",
            "Epoch 14/300\n",
            "504/504 [==============================] - 7s 15ms/step - loss: 0.5063 - binary_accuracy: 0.7902 - val_loss: 0.5162 - val_binary_accuracy: 0.7831 - lr: 0.0050\n",
            "Epoch 15/300\n",
            "504/504 [==============================] - 7s 14ms/step - loss: 0.5064 - binary_accuracy: 0.7901 - val_loss: 0.5167 - val_binary_accuracy: 0.7831 - lr: 0.0050\n",
            "Epoch 16/300\n",
            "504/504 [==============================] - 8s 15ms/step - loss: 0.5063 - binary_accuracy: 0.7902 - val_loss: 0.5156 - val_binary_accuracy: 0.7831 - lr: 0.0050\n",
            "Epoch 17/300\n",
            "504/504 [==============================] - 8s 15ms/step - loss: 0.5065 - binary_accuracy: 0.7902 - val_loss: 0.5152 - val_binary_accuracy: 0.7831 - lr: 0.0050\n",
            "Epoch 18/300\n",
            "504/504 [==============================] - 8s 16ms/step - loss: 0.5058 - binary_accuracy: 0.7902 - val_loss: 0.5186 - val_binary_accuracy: 0.7831 - lr: 0.0050\n",
            "Epoch 19/300\n",
            "504/504 [==============================] - 8s 16ms/step - loss: 0.5062 - binary_accuracy: 0.7902 - val_loss: 0.5156 - val_binary_accuracy: 0.7831 - lr: 0.0050\n",
            "Epoch 20/300\n",
            "504/504 [==============================] - 8s 16ms/step - loss: 0.5063 - binary_accuracy: 0.7902 - val_loss: 0.5234 - val_binary_accuracy: 0.7831 - lr: 0.0050\n",
            "Epoch 21/300\n",
            "504/504 [==============================] - 8s 16ms/step - loss: 0.5067 - binary_accuracy: 0.7902 - val_loss: 0.5160 - val_binary_accuracy: 0.7831 - lr: 0.0050\n",
            "Epoch 22/300\n",
            "501/504 [============================>.] - ETA: 0s - loss: 0.5064 - binary_accuracy: 0.7899\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "504/504 [==============================] - 7s 15ms/step - loss: 0.5060 - binary_accuracy: 0.7902 - val_loss: 0.5156 - val_binary_accuracy: 0.7831 - lr: 0.0050\n",
            "Epoch 23/300\n",
            "504/504 [==============================] - 7s 15ms/step - loss: 0.5050 - binary_accuracy: 0.7902 - val_loss: 0.5197 - val_binary_accuracy: 0.7831 - lr: 0.0025\n",
            "Epoch 24/300\n",
            "504/504 [==============================] - 8s 15ms/step - loss: 0.5054 - binary_accuracy: 0.7902 - val_loss: 0.5152 - val_binary_accuracy: 0.7831 - lr: 0.0025\n",
            "Epoch 25/300\n",
            "504/504 [==============================] - 9s 18ms/step - loss: 0.5053 - binary_accuracy: 0.7902 - val_loss: 0.5155 - val_binary_accuracy: 0.7831 - lr: 0.0025\n",
            "Epoch 26/300\n",
            "504/504 [==============================] - 7s 15ms/step - loss: 0.5053 - binary_accuracy: 0.7902 - val_loss: 0.5153 - val_binary_accuracy: 0.7831 - lr: 0.0025\n",
            "Epoch 27/300\n",
            "502/504 [============================>.] - ETA: 0s - loss: 0.5060 - binary_accuracy: 0.7901\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "504/504 [==============================] - 8s 15ms/step - loss: 0.5059 - binary_accuracy: 0.7902 - val_loss: 0.5180 - val_binary_accuracy: 0.7831 - lr: 0.0025\n",
            "Epoch 28/300\n",
            "504/504 [==============================] - 7s 14ms/step - loss: 0.5053 - binary_accuracy: 0.7902 - val_loss: 0.5152 - val_binary_accuracy: 0.7831 - lr: 0.0012\n",
            "Epoch 29/300\n",
            "504/504 [==============================] - 7s 14ms/step - loss: 0.5056 - binary_accuracy: 0.7902 - val_loss: 0.5167 - val_binary_accuracy: 0.7831 - lr: 0.0012\n",
            "Epoch 30/300\n",
            "504/504 [==============================] - 7s 14ms/step - loss: 0.5056 - binary_accuracy: 0.7902 - val_loss: 0.5151 - val_binary_accuracy: 0.7831 - lr: 0.0012\n",
            "Epoch 31/300\n",
            "504/504 [==============================] - 7s 15ms/step - loss: 0.5050 - binary_accuracy: 0.7902 - val_loss: 0.5153 - val_binary_accuracy: 0.7831 - lr: 0.0012\n",
            "Epoch 32/300\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.5048 - binary_accuracy: 0.7902\n",
            "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "504/504 [==============================] - 9s 17ms/step - loss: 0.5048 - binary_accuracy: 0.7902 - val_loss: 0.5156 - val_binary_accuracy: 0.7831 - lr: 0.0012\n",
            "Epoch 33/300\n",
            "504/504 [==============================] - 7s 14ms/step - loss: 0.5051 - binary_accuracy: 0.7902 - val_loss: 0.5153 - val_binary_accuracy: 0.7831 - lr: 6.2500e-04\n",
            "Epoch 34/300\n",
            "504/504 [==============================] - 7s 14ms/step - loss: 0.5053 - binary_accuracy: 0.7902 - val_loss: 0.5154 - val_binary_accuracy: 0.7831 - lr: 6.2500e-04\n",
            "Epoch 35/300\n",
            "504/504 [==============================] - 7s 15ms/step - loss: 0.5052 - binary_accuracy: 0.7902 - val_loss: 0.5154 - val_binary_accuracy: 0.7831 - lr: 6.2500e-04\n",
            "Epoch 36/300\n",
            "504/504 [==============================] - 7s 15ms/step - loss: 0.5056 - binary_accuracy: 0.7902 - val_loss: 0.5165 - val_binary_accuracy: 0.7831 - lr: 6.2500e-04\n",
            "Epoch 37/300\n",
            "500/504 [============================>.] - ETA: 0s - loss: 0.5054 - binary_accuracy: 0.7898\n",
            "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
            "504/504 [==============================] - 8s 16ms/step - loss: 0.5050 - binary_accuracy: 0.7902 - val_loss: 0.5155 - val_binary_accuracy: 0.7831 - lr: 6.2500e-04\n",
            "Epoch 38/300\n",
            "504/504 [==============================] - 8s 16ms/step - loss: 0.5051 - binary_accuracy: 0.7902 - val_loss: 0.5152 - val_binary_accuracy: 0.7831 - lr: 3.1250e-04\n",
            "Epoch 39/300\n",
            "504/504 [==============================] - 8s 16ms/step - loss: 0.5048 - binary_accuracy: 0.7902 - val_loss: 0.5151 - val_binary_accuracy: 0.7831 - lr: 3.1250e-04\n",
            "Epoch 40/300\n",
            "504/504 [==============================] - 8s 16ms/step - loss: 0.5056 - binary_accuracy: 0.7902 - val_loss: 0.5152 - val_binary_accuracy: 0.7831 - lr: 3.1250e-04\n",
            "Epoch 41/300\n",
            "504/504 [==============================] - 9s 17ms/step - loss: 0.5053 - binary_accuracy: 0.7902 - val_loss: 0.5153 - val_binary_accuracy: 0.7831 - lr: 3.1250e-04\n",
            "Epoch 42/300\n",
            "503/504 [============================>.] - ETA: 0s - loss: 0.5052 - binary_accuracy: 0.7899\n",
            "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
            "504/504 [==============================] - 8s 16ms/step - loss: 0.5049 - binary_accuracy: 0.7902 - val_loss: 0.5154 - val_binary_accuracy: 0.7831 - lr: 3.1250e-04\n",
            "Epoch 43/300\n",
            "504/504 [==============================] - 8s 17ms/step - loss: 0.5053 - binary_accuracy: 0.7902 - val_loss: 0.5152 - val_binary_accuracy: 0.7831 - lr: 1.5625e-04\n",
            "Epoch 44/300\n",
            "504/504 [==============================] - 8s 16ms/step - loss: 0.5057 - binary_accuracy: 0.7902 - val_loss: 0.5153 - val_binary_accuracy: 0.7831 - lr: 1.5625e-04\n",
            "Epoch 45/300\n",
            "504/504 [==============================] - 8s 16ms/step - loss: 0.5051 - binary_accuracy: 0.7902 - val_loss: 0.5152 - val_binary_accuracy: 0.7831 - lr: 1.5625e-04\n",
            "Epoch 46/300\n",
            "504/504 [==============================] - 8s 17ms/step - loss: 0.5052 - binary_accuracy: 0.7902 - val_loss: 0.5154 - val_binary_accuracy: 0.7831 - lr: 1.5625e-04\n",
            "Epoch 47/300\n",
            "503/504 [============================>.] - ETA: 0s - loss: 0.5050 - binary_accuracy: 0.7902\n",
            "Epoch 47: ReduceLROnPlateau reducing learning rate to 7.812499825377017e-05.\n",
            "504/504 [==============================] - 8s 16ms/step - loss: 0.5051 - binary_accuracy: 0.7902 - val_loss: 0.5155 - val_binary_accuracy: 0.7831 - lr: 1.5625e-04\n",
            "Epoch 48/300\n",
            "504/504 [==============================] - 8s 17ms/step - loss: 0.5051 - binary_accuracy: 0.7902 - val_loss: 0.5153 - val_binary_accuracy: 0.7831 - lr: 7.8125e-05\n",
            "Epoch 49/300\n",
            "504/504 [==============================] - 9s 19ms/step - loss: 0.5051 - binary_accuracy: 0.7902 - val_loss: 0.5154 - val_binary_accuracy: 0.7831 - lr: 7.8125e-05\n",
            "Epoch 50/300\n",
            "504/504 [==============================] - 8s 15ms/step - loss: 0.5053 - binary_accuracy: 0.7902 - val_loss: 0.5154 - val_binary_accuracy: 0.7831 - lr: 7.8125e-05\n",
            "Epoch 51/300\n",
            "503/504 [============================>.] - ETA: 0s - loss: 0.5049 - binary_accuracy: 0.7900Restoring model weights from the end of the best epoch: 39.\n",
            "504/504 [==============================] - 8s 16ms/step - loss: 0.5047 - binary_accuracy: 0.7902 - val_loss: 0.5154 - val_binary_accuracy: 0.7831 - lr: 7.8125e-05\n",
            "Epoch 51: early stopping\n",
            "Min val loss: 0.5151128768920898\n",
            "650/650 [==============================] - 4s 4ms/step\n",
            "Fold 5\n",
            "Epoch 1/300\n",
            "487/487 [==============================] - 18s 19ms/step - loss: 0.5270 - binary_accuracy: 0.7801 - val_loss: 0.5082 - val_binary_accuracy: 0.7937 - lr: 0.0100\n",
            "Epoch 2/300\n",
            "487/487 [==============================] - 9s 19ms/step - loss: 0.5178 - binary_accuracy: 0.7827 - val_loss: 0.5094 - val_binary_accuracy: 0.7937 - lr: 0.0100\n",
            "Epoch 3/300\n",
            "487/487 [==============================] - 8s 17ms/step - loss: 0.5190 - binary_accuracy: 0.7828 - val_loss: 0.5023 - val_binary_accuracy: 0.7937 - lr: 0.0100\n",
            "Epoch 4/300\n",
            "487/487 [==============================] - 8s 17ms/step - loss: 0.5185 - binary_accuracy: 0.7829 - val_loss: 0.5145 - val_binary_accuracy: 0.7937 - lr: 0.0100\n",
            "Epoch 5/300\n",
            "487/487 [==============================] - 8s 17ms/step - loss: 0.5169 - binary_accuracy: 0.7828 - val_loss: 0.5020 - val_binary_accuracy: 0.7937 - lr: 0.0100\n",
            "Epoch 6/300\n",
            "487/487 [==============================] - 8s 16ms/step - loss: 0.5172 - binary_accuracy: 0.7829 - val_loss: 0.5022 - val_binary_accuracy: 0.7937 - lr: 0.0100\n",
            "Epoch 7/300\n",
            "487/487 [==============================] - 8s 16ms/step - loss: 0.5182 - binary_accuracy: 0.7826 - val_loss: 0.5058 - val_binary_accuracy: 0.7937 - lr: 0.0100\n",
            "Epoch 8/300\n",
            "487/487 [==============================] - 9s 19ms/step - loss: 0.5178 - binary_accuracy: 0.7829 - val_loss: 0.5098 - val_binary_accuracy: 0.7937 - lr: 0.0100\n",
            "Epoch 9/300\n",
            "487/487 [==============================] - 8s 17ms/step - loss: 0.5172 - binary_accuracy: 0.7828 - val_loss: 0.5043 - val_binary_accuracy: 0.7937 - lr: 0.0100\n",
            "Epoch 10/300\n",
            "487/487 [==============================] - ETA: 0s - loss: 0.5184 - binary_accuracy: 0.7828\n",
            "Epoch 10: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "487/487 [==============================] - 8s 16ms/step - loss: 0.5184 - binary_accuracy: 0.7828 - val_loss: 0.5052 - val_binary_accuracy: 0.7937 - lr: 0.0100\n",
            "Epoch 11/300\n",
            "487/487 [==============================] - 7s 15ms/step - loss: 0.5174 - binary_accuracy: 0.7829 - val_loss: 0.5020 - val_binary_accuracy: 0.7937 - lr: 0.0050\n",
            "Epoch 12/300\n",
            "487/487 [==============================] - 8s 16ms/step - loss: 0.5169 - binary_accuracy: 0.7829 - val_loss: 0.5017 - val_binary_accuracy: 0.7937 - lr: 0.0050\n",
            "Epoch 13/300\n",
            "487/487 [==============================] - 7s 15ms/step - loss: 0.5163 - binary_accuracy: 0.7829 - val_loss: 0.5016 - val_binary_accuracy: 0.7937 - lr: 0.0050\n",
            "Epoch 14/300\n",
            "487/487 [==============================] - 7s 14ms/step - loss: 0.5159 - binary_accuracy: 0.7829 - val_loss: 0.5019 - val_binary_accuracy: 0.7937 - lr: 0.0050\n",
            "Epoch 15/300\n",
            "487/487 [==============================] - 8s 15ms/step - loss: 0.5165 - binary_accuracy: 0.7829 - val_loss: 0.5017 - val_binary_accuracy: 0.7937 - lr: 0.0050\n",
            "Epoch 16/300\n",
            "487/487 [==============================] - 7s 15ms/step - loss: 0.5161 - binary_accuracy: 0.7829 - val_loss: 0.5014 - val_binary_accuracy: 0.7937 - lr: 0.0050\n",
            "Epoch 17/300\n",
            "487/487 [==============================] - 7s 15ms/step - loss: 0.5160 - binary_accuracy: 0.7829 - val_loss: 0.5019 - val_binary_accuracy: 0.7937 - lr: 0.0050\n",
            "Epoch 18/300\n",
            "487/487 [==============================] - 8s 16ms/step - loss: 0.5158 - binary_accuracy: 0.7829 - val_loss: 0.5074 - val_binary_accuracy: 0.7937 - lr: 0.0050\n",
            "Epoch 19/300\n",
            "487/487 [==============================] - 9s 19ms/step - loss: 0.5156 - binary_accuracy: 0.7829 - val_loss: 0.5139 - val_binary_accuracy: 0.7937 - lr: 0.0050\n",
            "Epoch 20/300\n",
            "487/487 [==============================] - 10s 20ms/step - loss: 0.5164 - binary_accuracy: 0.7829 - val_loss: 0.5186 - val_binary_accuracy: 0.7937 - lr: 0.0050\n",
            "Epoch 21/300\n",
            "484/487 [============================>.] - ETA: 0s - loss: 0.5166 - binary_accuracy: 0.7827\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "487/487 [==============================] - 8s 16ms/step - loss: 0.5164 - binary_accuracy: 0.7829 - val_loss: 0.5025 - val_binary_accuracy: 0.7937 - lr: 0.0050\n",
            "Epoch 22/300\n",
            "487/487 [==============================] - 8s 16ms/step - loss: 0.5154 - binary_accuracy: 0.7829 - val_loss: 0.5021 - val_binary_accuracy: 0.7937 - lr: 0.0025\n",
            "Epoch 23/300\n",
            "487/487 [==============================] - 7s 15ms/step - loss: 0.5156 - binary_accuracy: 0.7829 - val_loss: 0.5012 - val_binary_accuracy: 0.7937 - lr: 0.0025\n",
            "Epoch 24/300\n",
            "487/487 [==============================] - 7s 15ms/step - loss: 0.5153 - binary_accuracy: 0.7829 - val_loss: 0.5013 - val_binary_accuracy: 0.7937 - lr: 0.0025\n",
            "Epoch 25/300\n",
            "487/487 [==============================] - 8s 16ms/step - loss: 0.5156 - binary_accuracy: 0.7829 - val_loss: 0.5017 - val_binary_accuracy: 0.7937 - lr: 0.0025\n",
            "Epoch 26/300\n",
            "487/487 [==============================] - 9s 19ms/step - loss: 0.5151 - binary_accuracy: 0.7829 - val_loss: 0.5034 - val_binary_accuracy: 0.7937 - lr: 0.0025\n",
            "Epoch 27/300\n",
            "487/487 [==============================] - 7s 15ms/step - loss: 0.5151 - binary_accuracy: 0.7829 - val_loss: 0.5025 - val_binary_accuracy: 0.7937 - lr: 0.0025\n",
            "Epoch 28/300\n",
            "486/487 [============================>.] - ETA: 0s - loss: 0.5158 - binary_accuracy: 0.7829\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "487/487 [==============================] - 7s 15ms/step - loss: 0.5158 - binary_accuracy: 0.7829 - val_loss: 0.5012 - val_binary_accuracy: 0.7937 - lr: 0.0025\n",
            "Epoch 29/300\n",
            "487/487 [==============================] - 7s 14ms/step - loss: 0.5150 - binary_accuracy: 0.7829 - val_loss: 0.5019 - val_binary_accuracy: 0.7937 - lr: 0.0012\n",
            "Epoch 30/300\n",
            "487/487 [==============================] - 7s 15ms/step - loss: 0.5154 - binary_accuracy: 0.7829 - val_loss: 0.5012 - val_binary_accuracy: 0.7937 - lr: 0.0012\n",
            "Epoch 31/300\n",
            "487/487 [==============================] - 8s 15ms/step - loss: 0.5154 - binary_accuracy: 0.7829 - val_loss: 0.5011 - val_binary_accuracy: 0.7937 - lr: 0.0012\n",
            "Epoch 32/300\n",
            "487/487 [==============================] - 7s 14ms/step - loss: 0.5152 - binary_accuracy: 0.7829 - val_loss: 0.5011 - val_binary_accuracy: 0.7937 - lr: 0.0012\n",
            "Epoch 33/300\n",
            "487/487 [==============================] - 7s 14ms/step - loss: 0.5151 - binary_accuracy: 0.7828 - val_loss: 0.5014 - val_binary_accuracy: 0.7937 - lr: 0.0012\n",
            "Epoch 34/300\n",
            "487/487 [==============================] - 7s 15ms/step - loss: 0.5145 - binary_accuracy: 0.7828 - val_loss: 0.5017 - val_binary_accuracy: 0.7937 - lr: 0.0012\n",
            "Epoch 35/300\n",
            "487/487 [==============================] - 7s 14ms/step - loss: 0.5155 - binary_accuracy: 0.7829 - val_loss: 0.5013 - val_binary_accuracy: 0.7937 - lr: 0.0012\n",
            "Epoch 36/300\n",
            "487/487 [==============================] - ETA: 0s - loss: 0.5154 - binary_accuracy: 0.7828\n",
            "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "487/487 [==============================] - 7s 15ms/step - loss: 0.5154 - binary_accuracy: 0.7828 - val_loss: 0.5011 - val_binary_accuracy: 0.7937 - lr: 0.0012\n",
            "Epoch 37/300\n",
            "487/487 [==============================] - 7s 15ms/step - loss: 0.5151 - binary_accuracy: 0.7829 - val_loss: 0.5014 - val_binary_accuracy: 0.7937 - lr: 6.2500e-04\n",
            "Epoch 38/300\n",
            "487/487 [==============================] - 7s 15ms/step - loss: 0.5146 - binary_accuracy: 0.7829 - val_loss: 0.5014 - val_binary_accuracy: 0.7937 - lr: 6.2500e-04\n",
            "Epoch 39/300\n",
            "487/487 [==============================] - 7s 15ms/step - loss: 0.5148 - binary_accuracy: 0.7829 - val_loss: 0.5012 - val_binary_accuracy: 0.7937 - lr: 6.2500e-04\n",
            "Epoch 40/300\n",
            "487/487 [==============================] - 7s 15ms/step - loss: 0.5150 - binary_accuracy: 0.7829 - val_loss: 0.5009 - val_binary_accuracy: 0.7937 - lr: 6.2500e-04\n",
            "Epoch 41/300\n",
            "487/487 [==============================] - 8s 16ms/step - loss: 0.5147 - binary_accuracy: 0.7829 - val_loss: 0.5014 - val_binary_accuracy: 0.7937 - lr: 6.2500e-04\n",
            "Epoch 42/300\n",
            "487/487 [==============================] - 8s 15ms/step - loss: 0.5149 - binary_accuracy: 0.7829 - val_loss: 0.5010 - val_binary_accuracy: 0.7937 - lr: 6.2500e-04\n",
            "Epoch 43/300\n",
            "487/487 [==============================] - 7s 15ms/step - loss: 0.5151 - binary_accuracy: 0.7829 - val_loss: 0.5017 - val_binary_accuracy: 0.7937 - lr: 6.2500e-04\n",
            "Epoch 44/300\n",
            "487/487 [==============================] - 8s 15ms/step - loss: 0.5149 - binary_accuracy: 0.7829 - val_loss: 0.5012 - val_binary_accuracy: 0.7937 - lr: 6.2500e-04\n",
            "Epoch 45/300\n",
            "483/487 [============================>.] - ETA: 0s - loss: 0.5153 - binary_accuracy: 0.7827\n",
            "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
            "487/487 [==============================] - 9s 19ms/step - loss: 0.5152 - binary_accuracy: 0.7829 - val_loss: 0.5017 - val_binary_accuracy: 0.7937 - lr: 6.2500e-04\n",
            "Epoch 46/300\n",
            "487/487 [==============================] - 7s 15ms/step - loss: 0.5152 - binary_accuracy: 0.7829 - val_loss: 0.5013 - val_binary_accuracy: 0.7937 - lr: 3.1250e-04\n",
            "Epoch 47/300\n",
            "487/487 [==============================] - 7s 14ms/step - loss: 0.5152 - binary_accuracy: 0.7829 - val_loss: 0.5014 - val_binary_accuracy: 0.7937 - lr: 3.1250e-04\n",
            "Epoch 48/300\n",
            "487/487 [==============================] - 7s 14ms/step - loss: 0.5145 - binary_accuracy: 0.7829 - val_loss: 0.5015 - val_binary_accuracy: 0.7937 - lr: 3.1250e-04\n",
            "Epoch 49/300\n",
            "487/487 [==============================] - 7s 15ms/step - loss: 0.5150 - binary_accuracy: 0.7829 - val_loss: 0.5016 - val_binary_accuracy: 0.7937 - lr: 3.1250e-04\n",
            "Epoch 50/300\n",
            "483/487 [============================>.] - ETA: 0s - loss: 0.5147 - binary_accuracy: 0.7827\n",
            "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.00015624999650754035.\n",
            "487/487 [==============================] - 7s 15ms/step - loss: 0.5145 - binary_accuracy: 0.7829 - val_loss: 0.5014 - val_binary_accuracy: 0.7937 - lr: 3.1250e-04\n",
            "Epoch 51/300\n",
            "487/487 [==============================] - 9s 19ms/step - loss: 0.5153 - binary_accuracy: 0.7829 - val_loss: 0.5014 - val_binary_accuracy: 0.7937 - lr: 1.5625e-04\n",
            "Epoch 52/300\n",
            "486/487 [============================>.] - ETA: 0s - loss: 0.5147 - binary_accuracy: 0.7829Restoring model weights from the end of the best epoch: 40.\n",
            "487/487 [==============================] - 8s 16ms/step - loss: 0.5147 - binary_accuracy: 0.7829 - val_loss: 0.5015 - val_binary_accuracy: 0.7937 - lr: 1.5625e-04\n",
            "Epoch 52: early stopping\n",
            "Min val loss: 0.5009311437606812\n",
            "650/650 [==============================] - 4s 4ms/step\n",
            "Fold 6\n",
            "Epoch 1/300\n",
            "507/507 [==============================] - 18s 19ms/step - loss: 0.5242 - binary_accuracy: 0.7828 - val_loss: 0.5073 - val_binary_accuracy: 0.7912 - lr: 0.0100\n",
            "Epoch 2/300\n",
            "507/507 [==============================] - 8s 16ms/step - loss: 0.5171 - binary_accuracy: 0.7852 - val_loss: 0.5070 - val_binary_accuracy: 0.7912 - lr: 0.0100\n",
            "Epoch 3/300\n",
            "507/507 [==============================] - 8s 16ms/step - loss: 0.5160 - binary_accuracy: 0.7847 - val_loss: 0.5108 - val_binary_accuracy: 0.7912 - lr: 0.0100\n",
            "Epoch 4/300\n",
            "507/507 [==============================] - 8s 16ms/step - loss: 0.5160 - binary_accuracy: 0.7850 - val_loss: 0.5186 - val_binary_accuracy: 0.7912 - lr: 0.0100\n",
            "Epoch 5/300\n",
            "507/507 [==============================] - 8s 16ms/step - loss: 0.5154 - binary_accuracy: 0.7849 - val_loss: 0.5107 - val_binary_accuracy: 0.7912 - lr: 0.0100\n",
            "Epoch 6/300\n",
            "507/507 [==============================] - 8s 15ms/step - loss: 0.5153 - binary_accuracy: 0.7850 - val_loss: 0.5546 - val_binary_accuracy: 0.7912 - lr: 0.0100\n",
            "Epoch 7/300\n",
            "507/507 [==============================] - 8s 15ms/step - loss: 0.5145 - binary_accuracy: 0.7850 - val_loss: 0.5053 - val_binary_accuracy: 0.7912 - lr: 0.0100\n",
            "Epoch 8/300\n",
            "507/507 [==============================] - 8s 16ms/step - loss: 0.5148 - binary_accuracy: 0.7850 - val_loss: 0.5058 - val_binary_accuracy: 0.7914 - lr: 0.0100\n",
            "Epoch 9/300\n",
            "507/507 [==============================] - 8s 16ms/step - loss: 0.5151 - binary_accuracy: 0.7849 - val_loss: 0.5043 - val_binary_accuracy: 0.7912 - lr: 0.0100\n",
            "Epoch 10/300\n",
            "507/507 [==============================] - 8s 16ms/step - loss: 0.5150 - binary_accuracy: 0.7850 - val_loss: 0.5049 - val_binary_accuracy: 0.7912 - lr: 0.0100\n",
            "Epoch 11/300\n",
            "507/507 [==============================] - 8s 16ms/step - loss: 0.5161 - binary_accuracy: 0.7850 - val_loss: 0.5049 - val_binary_accuracy: 0.7912 - lr: 0.0100\n",
            "Epoch 12/300\n",
            "507/507 [==============================] - 8s 16ms/step - loss: 0.5155 - binary_accuracy: 0.7849 - val_loss: 0.5062 - val_binary_accuracy: 0.7912 - lr: 0.0100\n",
            "Epoch 13/300\n",
            "507/507 [==============================] - 9s 17ms/step - loss: 0.5148 - binary_accuracy: 0.7850 - val_loss: 0.5069 - val_binary_accuracy: 0.7912 - lr: 0.0100\n",
            "Epoch 14/300\n",
            "506/507 [============================>.] - ETA: 0s - loss: 0.5167 - binary_accuracy: 0.7842\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "507/507 [==============================] - 11s 22ms/step - loss: 0.5167 - binary_accuracy: 0.7842 - val_loss: 0.5095 - val_binary_accuracy: 0.7912 - lr: 0.0100\n",
            "Epoch 15/300\n",
            "507/507 [==============================] - 8s 16ms/step - loss: 0.5145 - binary_accuracy: 0.7850 - val_loss: 0.5039 - val_binary_accuracy: 0.7912 - lr: 0.0050\n",
            "Epoch 16/300\n",
            "507/507 [==============================] - 8s 17ms/step - loss: 0.5148 - binary_accuracy: 0.7850 - val_loss: 0.5044 - val_binary_accuracy: 0.7912 - lr: 0.0050\n",
            "Epoch 17/300\n",
            "507/507 [==============================] - 8s 16ms/step - loss: 0.5139 - binary_accuracy: 0.7850 - val_loss: 0.5037 - val_binary_accuracy: 0.7912 - lr: 0.0050\n",
            "Epoch 18/300\n",
            "507/507 [==============================] - 8s 16ms/step - loss: 0.5134 - binary_accuracy: 0.7850 - val_loss: 0.5037 - val_binary_accuracy: 0.7912 - lr: 0.0050\n",
            "Epoch 19/300\n",
            "507/507 [==============================] - 10s 19ms/step - loss: 0.5141 - binary_accuracy: 0.7850 - val_loss: 0.5050 - val_binary_accuracy: 0.7912 - lr: 0.0050\n",
            "Epoch 20/300\n",
            "507/507 [==============================] - 8s 15ms/step - loss: 0.5140 - binary_accuracy: 0.7850 - val_loss: 0.5034 - val_binary_accuracy: 0.7912 - lr: 0.0050\n",
            "Epoch 21/300\n",
            "507/507 [==============================] - 8s 15ms/step - loss: 0.5138 - binary_accuracy: 0.7850 - val_loss: 0.5077 - val_binary_accuracy: 0.7912 - lr: 0.0050\n",
            "Epoch 22/300\n",
            "507/507 [==============================] - 8s 15ms/step - loss: 0.5139 - binary_accuracy: 0.7850 - val_loss: 0.5046 - val_binary_accuracy: 0.7912 - lr: 0.0050\n",
            "Epoch 23/300\n",
            "507/507 [==============================] - 8s 16ms/step - loss: 0.5137 - binary_accuracy: 0.7850 - val_loss: 0.5044 - val_binary_accuracy: 0.7912 - lr: 0.0050\n",
            "Epoch 24/300\n",
            "507/507 [==============================] - 8s 15ms/step - loss: 0.5137 - binary_accuracy: 0.7850 - val_loss: 0.5039 - val_binary_accuracy: 0.7912 - lr: 0.0050\n",
            "Epoch 25/300\n",
            "507/507 [==============================] - ETA: 0s - loss: 0.5137 - binary_accuracy: 0.7850\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "507/507 [==============================] - 8s 16ms/step - loss: 0.5137 - binary_accuracy: 0.7850 - val_loss: 0.5076 - val_binary_accuracy: 0.7912 - lr: 0.0050\n",
            "Epoch 26/300\n",
            "507/507 [==============================] - 8s 15ms/step - loss: 0.5135 - binary_accuracy: 0.7850 - val_loss: 0.5035 - val_binary_accuracy: 0.7912 - lr: 0.0025\n",
            "Epoch 27/300\n",
            "507/507 [==============================] - 8s 16ms/step - loss: 0.5131 - binary_accuracy: 0.7850 - val_loss: 0.5058 - val_binary_accuracy: 0.7912 - lr: 0.0025\n",
            "Epoch 28/300\n",
            "507/507 [==============================] - 8s 15ms/step - loss: 0.5130 - binary_accuracy: 0.7850 - val_loss: 0.5037 - val_binary_accuracy: 0.7912 - lr: 0.0025\n",
            "Epoch 29/300\n",
            "507/507 [==============================] - 8s 16ms/step - loss: 0.5130 - binary_accuracy: 0.7850 - val_loss: 0.5057 - val_binary_accuracy: 0.7912 - lr: 0.0025\n",
            "Epoch 30/300\n",
            "505/507 [============================>.] - ETA: 0s - loss: 0.5135 - binary_accuracy: 0.7847\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "507/507 [==============================] - 7s 15ms/step - loss: 0.5129 - binary_accuracy: 0.7850 - val_loss: 0.5034 - val_binary_accuracy: 0.7912 - lr: 0.0025\n",
            "Epoch 31/300\n",
            "507/507 [==============================] - 8s 16ms/step - loss: 0.5129 - binary_accuracy: 0.7850 - val_loss: 0.5035 - val_binary_accuracy: 0.7912 - lr: 0.0012\n",
            "Epoch 32/300\n",
            "507/507 [==============================] - 8s 16ms/step - loss: 0.5127 - binary_accuracy: 0.7850 - val_loss: 0.5039 - val_binary_accuracy: 0.7912 - lr: 0.0012\n",
            "Epoch 33/300\n",
            "507/507 [==============================] - 8s 16ms/step - loss: 0.5131 - binary_accuracy: 0.7850 - val_loss: 0.5043 - val_binary_accuracy: 0.7912 - lr: 0.0012\n",
            "Epoch 34/300\n",
            "507/507 [==============================] - 8s 15ms/step - loss: 0.5128 - binary_accuracy: 0.7850 - val_loss: 0.5036 - val_binary_accuracy: 0.7912 - lr: 0.0012\n",
            "Epoch 35/300\n",
            "507/507 [==============================] - ETA: 0s - loss: 0.5129 - binary_accuracy: 0.7850\n",
            "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "507/507 [==============================] - 8s 16ms/step - loss: 0.5129 - binary_accuracy: 0.7850 - val_loss: 0.5040 - val_binary_accuracy: 0.7912 - lr: 0.0012\n",
            "Epoch 36/300\n",
            "507/507 [==============================] - 8s 15ms/step - loss: 0.5126 - binary_accuracy: 0.7850 - val_loss: 0.5043 - val_binary_accuracy: 0.7912 - lr: 6.2500e-04\n",
            "Epoch 37/300\n",
            "507/507 [==============================] - 10s 20ms/step - loss: 0.5127 - binary_accuracy: 0.7850 - val_loss: 0.5040 - val_binary_accuracy: 0.7912 - lr: 6.2500e-04\n",
            "Epoch 38/300\n",
            "507/507 [==============================] - 7s 15ms/step - loss: 0.5130 - binary_accuracy: 0.7850 - val_loss: 0.5040 - val_binary_accuracy: 0.7912 - lr: 6.2500e-04\n",
            "Epoch 39/300\n",
            "507/507 [==============================] - 8s 16ms/step - loss: 0.5126 - binary_accuracy: 0.7850 - val_loss: 0.5037 - val_binary_accuracy: 0.7912 - lr: 6.2500e-04\n",
            "Epoch 40/300\n",
            "505/507 [============================>.] - ETA: 0s - loss: 0.5132 - binary_accuracy: 0.7848\n",
            "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
            "507/507 [==============================] - 8s 16ms/step - loss: 0.5131 - binary_accuracy: 0.7850 - val_loss: 0.5043 - val_binary_accuracy: 0.7912 - lr: 6.2500e-04\n",
            "Epoch 41/300\n",
            "507/507 [==============================] - 8s 16ms/step - loss: 0.5127 - binary_accuracy: 0.7850 - val_loss: 0.5040 - val_binary_accuracy: 0.7912 - lr: 3.1250e-04\n",
            "Epoch 42/300\n",
            "503/507 [============================>.] - ETA: 0s - loss: 0.5132 - binary_accuracy: 0.7847Restoring model weights from the end of the best epoch: 30.\n",
            "507/507 [==============================] - 7s 15ms/step - loss: 0.5127 - binary_accuracy: 0.7850 - val_loss: 0.5041 - val_binary_accuracy: 0.7912 - lr: 3.1250e-04\n",
            "Epoch 42: early stopping\n",
            "Min val loss: 0.5033921599388123\n",
            "650/650 [==============================] - 5s 5ms/step\n",
            "Fold 7\n",
            "Epoch 1/300\n",
            "500/500 [==============================] - 17s 18ms/step - loss: 0.5292 - binary_accuracy: 0.7790 - val_loss: 0.5008 - val_binary_accuracy: 0.7963 - lr: 0.0100\n",
            "Epoch 2/300\n",
            "500/500 [==============================] - 8s 17ms/step - loss: 0.5201 - binary_accuracy: 0.7813 - val_loss: 0.5157 - val_binary_accuracy: 0.7963 - lr: 0.0100\n",
            "Epoch 3/300\n",
            "500/500 [==============================] - 8s 15ms/step - loss: 0.5190 - binary_accuracy: 0.7815 - val_loss: 0.5081 - val_binary_accuracy: 0.7963 - lr: 0.0100\n",
            "Epoch 4/300\n",
            "500/500 [==============================] - 8s 17ms/step - loss: 0.5200 - binary_accuracy: 0.7816 - val_loss: 0.5123 - val_binary_accuracy: 0.7963 - lr: 0.0100\n",
            "Epoch 5/300\n",
            "500/500 [==============================] - 8s 16ms/step - loss: 0.5195 - binary_accuracy: 0.7815 - val_loss: 0.5021 - val_binary_accuracy: 0.7963 - lr: 0.0100\n",
            "Epoch 6/300\n",
            "499/500 [============================>.] - ETA: 0s - loss: 0.5200 - binary_accuracy: 0.7815\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "500/500 [==============================] - 8s 16ms/step - loss: 0.5200 - binary_accuracy: 0.7815 - val_loss: 0.5224 - val_binary_accuracy: 0.7963 - lr: 0.0100\n",
            "Epoch 7/300\n",
            "500/500 [==============================] - 8s 16ms/step - loss: 0.5180 - binary_accuracy: 0.7815 - val_loss: 0.5073 - val_binary_accuracy: 0.7963 - lr: 0.0050\n",
            "Epoch 8/300\n",
            "500/500 [==============================] - 7s 14ms/step - loss: 0.5178 - binary_accuracy: 0.7815 - val_loss: 0.4987 - val_binary_accuracy: 0.7963 - lr: 0.0050\n",
            "Epoch 9/300\n",
            "500/500 [==============================] - 7s 15ms/step - loss: 0.5176 - binary_accuracy: 0.7815 - val_loss: 0.5169 - val_binary_accuracy: 0.7963 - lr: 0.0050\n",
            "Epoch 10/300\n",
            "500/500 [==============================] - 8s 15ms/step - loss: 0.5175 - binary_accuracy: 0.7815 - val_loss: 0.4994 - val_binary_accuracy: 0.7963 - lr: 0.0050\n",
            "Epoch 11/300\n",
            "500/500 [==============================] - 7s 14ms/step - loss: 0.5175 - binary_accuracy: 0.7815 - val_loss: 0.5045 - val_binary_accuracy: 0.7963 - lr: 0.0050\n",
            "Epoch 12/300\n",
            "500/500 [==============================] - 8s 16ms/step - loss: 0.5176 - binary_accuracy: 0.7815 - val_loss: 0.4999 - val_binary_accuracy: 0.7963 - lr: 0.0050\n",
            "Epoch 13/300\n",
            "500/500 [==============================] - 8s 16ms/step - loss: 0.5173 - binary_accuracy: 0.7815 - val_loss: 0.4986 - val_binary_accuracy: 0.7963 - lr: 0.0050\n",
            "Epoch 14/300\n",
            "500/500 [==============================] - 8s 16ms/step - loss: 0.5182 - binary_accuracy: 0.7815 - val_loss: 0.5020 - val_binary_accuracy: 0.7963 - lr: 0.0050\n",
            "Epoch 15/300\n",
            "500/500 [==============================] - 8s 16ms/step - loss: 0.5175 - binary_accuracy: 0.7815 - val_loss: 0.4986 - val_binary_accuracy: 0.7963 - lr: 0.0050\n",
            "Epoch 16/300\n",
            "500/500 [==============================] - 8s 16ms/step - loss: 0.5170 - binary_accuracy: 0.7815 - val_loss: 0.5026 - val_binary_accuracy: 0.7963 - lr: 0.0050\n",
            "Epoch 17/300\n",
            "500/500 [==============================] - 9s 19ms/step - loss: 0.5180 - binary_accuracy: 0.7815 - val_loss: 0.5024 - val_binary_accuracy: 0.7963 - lr: 0.0050\n",
            "Epoch 18/300\n",
            "497/500 [============================>.] - ETA: 0s - loss: 0.5178 - binary_accuracy: 0.7814\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "500/500 [==============================] - 8s 16ms/step - loss: 0.5177 - binary_accuracy: 0.7815 - val_loss: 0.5005 - val_binary_accuracy: 0.7963 - lr: 0.0050\n",
            "Epoch 19/300\n",
            "500/500 [==============================] - 8s 16ms/step - loss: 0.5169 - binary_accuracy: 0.7815 - val_loss: 0.5050 - val_binary_accuracy: 0.7963 - lr: 0.0025\n",
            "Epoch 20/300\n",
            "500/500 [==============================] - 8s 17ms/step - loss: 0.5166 - binary_accuracy: 0.7815 - val_loss: 0.4986 - val_binary_accuracy: 0.7963 - lr: 0.0025\n",
            "Epoch 21/300\n",
            "500/500 [==============================] - 8s 17ms/step - loss: 0.5169 - binary_accuracy: 0.7815 - val_loss: 0.5033 - val_binary_accuracy: 0.7963 - lr: 0.0025\n",
            "Epoch 22/300\n",
            "500/500 [==============================] - 9s 18ms/step - loss: 0.5172 - binary_accuracy: 0.7815 - val_loss: 0.5018 - val_binary_accuracy: 0.7963 - lr: 0.0025\n",
            "Epoch 23/300\n",
            "500/500 [==============================] - ETA: 0s - loss: 0.5172 - binary_accuracy: 0.7815\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "500/500 [==============================] - 8s 17ms/step - loss: 0.5172 - binary_accuracy: 0.7815 - val_loss: 0.5036 - val_binary_accuracy: 0.7963 - lr: 0.0025\n",
            "Epoch 24/300\n",
            "500/500 [==============================] - 8s 16ms/step - loss: 0.5168 - binary_accuracy: 0.7815 - val_loss: 0.5010 - val_binary_accuracy: 0.7963 - lr: 0.0012\n",
            "Epoch 25/300\n",
            "497/500 [============================>.] - ETA: 0s - loss: 0.5170 - binary_accuracy: 0.7812Restoring model weights from the end of the best epoch: 13.\n",
            "500/500 [==============================] - 8s 16ms/step - loss: 0.5167 - binary_accuracy: 0.7815 - val_loss: 0.5012 - val_binary_accuracy: 0.7963 - lr: 0.0012\n",
            "Epoch 25: early stopping\n",
            "Min val loss: 0.49859359860420227\n",
            "650/650 [==============================] - 3s 4ms/step\n",
            "Fold 8\n",
            "Epoch 1/300\n",
            "491/491 [==============================] - 19s 19ms/step - loss: 0.5198 - binary_accuracy: 0.7867 - val_loss: 0.5166 - val_binary_accuracy: 0.7856 - lr: 0.0100\n",
            "Epoch 2/300\n",
            "491/491 [==============================] - 8s 17ms/step - loss: 0.5121 - binary_accuracy: 0.7886 - val_loss: 0.5148 - val_binary_accuracy: 0.7856 - lr: 0.0100\n",
            "Epoch 3/300\n",
            "491/491 [==============================] - 8s 16ms/step - loss: 0.5112 - binary_accuracy: 0.7885 - val_loss: 0.5301 - val_binary_accuracy: 0.7856 - lr: 0.0100\n",
            "Epoch 4/300\n",
            "491/491 [==============================] - 8s 16ms/step - loss: 0.5118 - binary_accuracy: 0.7884 - val_loss: 0.5184 - val_binary_accuracy: 0.7856 - lr: 0.0100\n",
            "Epoch 5/300\n",
            "491/491 [==============================] - 8s 17ms/step - loss: 0.5116 - binary_accuracy: 0.7886 - val_loss: 0.5152 - val_binary_accuracy: 0.7856 - lr: 0.0100\n",
            "Epoch 6/300\n",
            "491/491 [==============================] - 8s 17ms/step - loss: 0.5111 - binary_accuracy: 0.7886 - val_loss: 0.5287 - val_binary_accuracy: 0.7856 - lr: 0.0100\n",
            "Epoch 7/300\n",
            "488/491 [============================>.] - ETA: 0s - loss: 0.5101 - binary_accuracy: 0.7886\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "491/491 [==============================] - 8s 17ms/step - loss: 0.5101 - binary_accuracy: 0.7886 - val_loss: 0.5216 - val_binary_accuracy: 0.7856 - lr: 0.0100\n",
            "Epoch 8/300\n",
            "491/491 [==============================] - 8s 17ms/step - loss: 0.5095 - binary_accuracy: 0.7886 - val_loss: 0.5195 - val_binary_accuracy: 0.7856 - lr: 0.0050\n",
            "Epoch 9/300\n",
            "491/491 [==============================] - 8s 16ms/step - loss: 0.5091 - binary_accuracy: 0.7886 - val_loss: 0.5122 - val_binary_accuracy: 0.7856 - lr: 0.0050\n",
            "Epoch 10/300\n",
            "491/491 [==============================] - 8s 17ms/step - loss: 0.5090 - binary_accuracy: 0.7886 - val_loss: 0.5168 - val_binary_accuracy: 0.7856 - lr: 0.0050\n",
            "Epoch 11/300\n",
            "491/491 [==============================] - 8s 16ms/step - loss: 0.5092 - binary_accuracy: 0.7886 - val_loss: 0.5120 - val_binary_accuracy: 0.7856 - lr: 0.0050\n",
            "Epoch 12/300\n",
            "491/491 [==============================] - 10s 20ms/step - loss: 0.5091 - binary_accuracy: 0.7886 - val_loss: 0.5119 - val_binary_accuracy: 0.7856 - lr: 0.0050\n",
            "Epoch 13/300\n",
            "491/491 [==============================] - 7s 15ms/step - loss: 0.5088 - binary_accuracy: 0.7886 - val_loss: 0.5125 - val_binary_accuracy: 0.7856 - lr: 0.0050\n",
            "Epoch 14/300\n",
            "491/491 [==============================] - 7s 15ms/step - loss: 0.5091 - binary_accuracy: 0.7886 - val_loss: 0.5158 - val_binary_accuracy: 0.7856 - lr: 0.0050\n",
            "Epoch 15/300\n",
            "491/491 [==============================] - 8s 16ms/step - loss: 0.5094 - binary_accuracy: 0.7886 - val_loss: 0.5136 - val_binary_accuracy: 0.7856 - lr: 0.0050\n",
            "Epoch 16/300\n",
            "489/491 [============================>.] - ETA: 0s - loss: 0.5105 - binary_accuracy: 0.7882\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "491/491 [==============================] - 8s 16ms/step - loss: 0.5100 - binary_accuracy: 0.7886 - val_loss: 0.5128 - val_binary_accuracy: 0.7856 - lr: 0.0050\n",
            "Epoch 17/300\n",
            "491/491 [==============================] - 9s 18ms/step - loss: 0.5098 - binary_accuracy: 0.7886 - val_loss: 0.5120 - val_binary_accuracy: 0.7856 - lr: 0.0025\n",
            "Epoch 18/300\n",
            "491/491 [==============================] - 8s 15ms/step - loss: 0.5094 - binary_accuracy: 0.7886 - val_loss: 0.5135 - val_binary_accuracy: 0.7856 - lr: 0.0025\n",
            "Epoch 19/300\n",
            "491/491 [==============================] - 7s 15ms/step - loss: 0.5095 - binary_accuracy: 0.7886 - val_loss: 0.5153 - val_binary_accuracy: 0.7856 - lr: 0.0025\n",
            "Epoch 20/300\n",
            "491/491 [==============================] - 8s 16ms/step - loss: 0.5084 - binary_accuracy: 0.7886 - val_loss: 0.5115 - val_binary_accuracy: 0.7856 - lr: 0.0025\n",
            "Epoch 21/300\n",
            "491/491 [==============================] - 7s 15ms/step - loss: 0.5091 - binary_accuracy: 0.7886 - val_loss: 0.5126 - val_binary_accuracy: 0.7856 - lr: 0.0025\n",
            "Epoch 22/300\n",
            "491/491 [==============================] - 7s 15ms/step - loss: 0.5097 - binary_accuracy: 0.7886 - val_loss: 0.5127 - val_binary_accuracy: 0.7856 - lr: 0.0025\n",
            "Epoch 23/300\n",
            "491/491 [==============================] - 7s 15ms/step - loss: 0.5100 - binary_accuracy: 0.7886 - val_loss: 0.5142 - val_binary_accuracy: 0.7856 - lr: 0.0025\n",
            "Epoch 24/300\n",
            "491/491 [==============================] - 7s 15ms/step - loss: 0.5095 - binary_accuracy: 0.7886 - val_loss: 0.5116 - val_binary_accuracy: 0.7856 - lr: 0.0025\n",
            "Epoch 25/300\n",
            "489/491 [============================>.] - ETA: 0s - loss: 0.5097 - binary_accuracy: 0.7886\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "491/491 [==============================] - 8s 15ms/step - loss: 0.5097 - binary_accuracy: 0.7886 - val_loss: 0.5118 - val_binary_accuracy: 0.7856 - lr: 0.0025\n",
            "Epoch 26/300\n",
            "491/491 [==============================] - 8s 16ms/step - loss: 0.5093 - binary_accuracy: 0.7886 - val_loss: 0.5125 - val_binary_accuracy: 0.7856 - lr: 0.0012\n",
            "Epoch 27/300\n",
            "491/491 [==============================] - 8s 16ms/step - loss: 0.5105 - binary_accuracy: 0.7886 - val_loss: 0.5117 - val_binary_accuracy: 0.7856 - lr: 0.0012\n",
            "Epoch 28/300\n",
            "491/491 [==============================] - 7s 15ms/step - loss: 0.5095 - binary_accuracy: 0.7886 - val_loss: 0.5123 - val_binary_accuracy: 0.7856 - lr: 0.0012\n",
            "Epoch 29/300\n",
            "491/491 [==============================] - 7s 15ms/step - loss: 0.5087 - binary_accuracy: 0.7886 - val_loss: 0.5116 - val_binary_accuracy: 0.7856 - lr: 0.0012\n",
            "Epoch 30/300\n",
            "487/491 [============================>.] - ETA: 0s - loss: 0.5096 - binary_accuracy: 0.7886\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "491/491 [==============================] - 8s 16ms/step - loss: 0.5094 - binary_accuracy: 0.7886 - val_loss: 0.5130 - val_binary_accuracy: 0.7856 - lr: 0.0012\n",
            "Epoch 31/300\n",
            "491/491 [==============================] - 7s 15ms/step - loss: 0.5093 - binary_accuracy: 0.7886 - val_loss: 0.5132 - val_binary_accuracy: 0.7856 - lr: 6.2500e-04\n",
            "Epoch 32/300\n",
            "488/491 [============================>.] - ETA: 0s - loss: 0.5092 - binary_accuracy: 0.7885Restoring model weights from the end of the best epoch: 20.\n",
            "491/491 [==============================] - 8s 16ms/step - loss: 0.5091 - binary_accuracy: 0.7886 - val_loss: 0.5123 - val_binary_accuracy: 0.7856 - lr: 6.2500e-04\n",
            "Epoch 32: early stopping\n",
            "Min val loss: 0.5114537477493286\n",
            "650/650 [==============================] - 3s 4ms/step\n",
            "Fold 9\n",
            "Epoch 1/300\n",
            "484/484 [==============================] - 17s 19ms/step - loss: 0.5241 - binary_accuracy: 0.7822 - val_loss: 0.5073 - val_binary_accuracy: 0.7906 - lr: 0.0100\n",
            "Epoch 2/300\n",
            "484/484 [==============================] - 9s 19ms/step - loss: 0.5160 - binary_accuracy: 0.7842 - val_loss: 0.5066 - val_binary_accuracy: 0.7906 - lr: 0.0100\n",
            "Epoch 3/300\n",
            "484/484 [==============================] - 8s 16ms/step - loss: 0.5149 - binary_accuracy: 0.7850 - val_loss: 0.5076 - val_binary_accuracy: 0.7906 - lr: 0.0100\n",
            "Epoch 4/300\n",
            "484/484 [==============================] - 7s 15ms/step - loss: 0.5141 - binary_accuracy: 0.7851 - val_loss: 0.5146 - val_binary_accuracy: 0.7906 - lr: 0.0100\n",
            "Epoch 5/300\n",
            "484/484 [==============================] - 7s 15ms/step - loss: 0.5140 - binary_accuracy: 0.7851 - val_loss: 0.5093 - val_binary_accuracy: 0.7906 - lr: 0.0100\n",
            "Epoch 6/300\n",
            "484/484 [==============================] - 8s 16ms/step - loss: 0.5138 - binary_accuracy: 0.7850 - val_loss: 0.5085 - val_binary_accuracy: 0.7906 - lr: 0.0100\n",
            "Epoch 7/300\n",
            "482/484 [============================>.] - ETA: 0s - loss: 0.5146 - binary_accuracy: 0.7848\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "484/484 [==============================] - 10s 21ms/step - loss: 0.5143 - binary_accuracy: 0.7851 - val_loss: 0.5074 - val_binary_accuracy: 0.7906 - lr: 0.0100\n",
            "Epoch 8/300\n",
            "484/484 [==============================] - 8s 16ms/step - loss: 0.5127 - binary_accuracy: 0.7851 - val_loss: 0.5072 - val_binary_accuracy: 0.7906 - lr: 0.0050\n",
            "Epoch 9/300\n",
            "484/484 [==============================] - 8s 16ms/step - loss: 0.5132 - binary_accuracy: 0.7851 - val_loss: 0.5079 - val_binary_accuracy: 0.7906 - lr: 0.0050\n",
            "Epoch 10/300\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 0.5121 - binary_accuracy: 0.7851 - val_loss: 0.5119 - val_binary_accuracy: 0.7906 - lr: 0.0050\n",
            "Epoch 11/300\n",
            "484/484 [==============================] - 7s 15ms/step - loss: 0.5125 - binary_accuracy: 0.7851 - val_loss: 0.5082 - val_binary_accuracy: 0.7906 - lr: 0.0050\n",
            "Epoch 12/300\n",
            "482/484 [============================>.] - ETA: 0s - loss: 0.5128 - binary_accuracy: 0.7851\n",
            "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 0.5127 - binary_accuracy: 0.7851 - val_loss: 0.5140 - val_binary_accuracy: 0.7906 - lr: 0.0050\n",
            "Epoch 13/300\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 0.5127 - binary_accuracy: 0.7851 - val_loss: 0.5064 - val_binary_accuracy: 0.7906 - lr: 0.0025\n",
            "Epoch 14/300\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 0.5121 - binary_accuracy: 0.7851 - val_loss: 0.5061 - val_binary_accuracy: 0.7906 - lr: 0.0025\n",
            "Epoch 15/300\n",
            "484/484 [==============================] - 7s 15ms/step - loss: 0.5117 - binary_accuracy: 0.7851 - val_loss: 0.5078 - val_binary_accuracy: 0.7906 - lr: 0.0025\n",
            "Epoch 16/300\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 0.5116 - binary_accuracy: 0.7851 - val_loss: 0.5063 - val_binary_accuracy: 0.7906 - lr: 0.0025\n",
            "Epoch 17/300\n",
            "484/484 [==============================] - 7s 15ms/step - loss: 0.5118 - binary_accuracy: 0.7851 - val_loss: 0.5086 - val_binary_accuracy: 0.7906 - lr: 0.0025\n",
            "Epoch 18/300\n",
            "484/484 [==============================] - 7s 15ms/step - loss: 0.5120 - binary_accuracy: 0.7851 - val_loss: 0.5080 - val_binary_accuracy: 0.7906 - lr: 0.0025\n",
            "Epoch 19/300\n",
            "482/484 [============================>.] - ETA: 0s - loss: 0.5119 - binary_accuracy: 0.7849\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 0.5117 - binary_accuracy: 0.7851 - val_loss: 0.5071 - val_binary_accuracy: 0.7906 - lr: 0.0025\n",
            "Epoch 20/300\n",
            "484/484 [==============================] - 7s 15ms/step - loss: 0.5119 - binary_accuracy: 0.7851 - val_loss: 0.5059 - val_binary_accuracy: 0.7906 - lr: 0.0012\n",
            "Epoch 21/300\n",
            "484/484 [==============================] - 7s 15ms/step - loss: 0.5113 - binary_accuracy: 0.7851 - val_loss: 0.5081 - val_binary_accuracy: 0.7906 - lr: 0.0012\n",
            "Epoch 22/300\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 0.5116 - binary_accuracy: 0.7851 - val_loss: 0.5074 - val_binary_accuracy: 0.7906 - lr: 0.0012\n",
            "Epoch 23/300\n",
            "484/484 [==============================] - 7s 15ms/step - loss: 0.5117 - binary_accuracy: 0.7851 - val_loss: 0.5061 - val_binary_accuracy: 0.7906 - lr: 0.0012\n",
            "Epoch 24/300\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 0.5117 - binary_accuracy: 0.7851 - val_loss: 0.5063 - val_binary_accuracy: 0.7906 - lr: 0.0012\n",
            "Epoch 25/300\n",
            "483/484 [============================>.] - ETA: 0s - loss: 0.5113 - binary_accuracy: 0.7851\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 0.5113 - binary_accuracy: 0.7851 - val_loss: 0.5071 - val_binary_accuracy: 0.7906 - lr: 0.0012\n",
            "Epoch 26/300\n",
            "484/484 [==============================] - 7s 15ms/step - loss: 0.5110 - binary_accuracy: 0.7851 - val_loss: 0.5060 - val_binary_accuracy: 0.7906 - lr: 6.2500e-04\n",
            "Epoch 27/300\n",
            "484/484 [==============================] - 9s 19ms/step - loss: 0.5119 - binary_accuracy: 0.7851 - val_loss: 0.5061 - val_binary_accuracy: 0.7906 - lr: 6.2500e-04\n",
            "Epoch 28/300\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 0.5116 - binary_accuracy: 0.7851 - val_loss: 0.5063 - val_binary_accuracy: 0.7906 - lr: 6.2500e-04\n",
            "Epoch 29/300\n",
            "484/484 [==============================] - 7s 13ms/step - loss: 0.5115 - binary_accuracy: 0.7851 - val_loss: 0.5062 - val_binary_accuracy: 0.7906 - lr: 6.2500e-04\n",
            "Epoch 30/300\n",
            "480/484 [============================>.] - ETA: 0s - loss: 0.5108 - binary_accuracy: 0.7852\n",
            "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0003124999930150807.\n",
            "484/484 [==============================] - 7s 15ms/step - loss: 0.5111 - binary_accuracy: 0.7851 - val_loss: 0.5061 - val_binary_accuracy: 0.7906 - lr: 6.2500e-04\n",
            "Epoch 31/300\n",
            "484/484 [==============================] - 6s 13ms/step - loss: 0.5112 - binary_accuracy: 0.7851 - val_loss: 0.5061 - val_binary_accuracy: 0.7906 - lr: 3.1250e-04\n",
            "Epoch 32/300\n",
            "482/484 [============================>.] - ETA: 0s - loss: 0.5111 - binary_accuracy: 0.7852Restoring model weights from the end of the best epoch: 20.\n",
            "484/484 [==============================] - 7s 14ms/step - loss: 0.5113 - binary_accuracy: 0.7851 - val_loss: 0.5061 - val_binary_accuracy: 0.7906 - lr: 3.1250e-04\n",
            "Epoch 32: early stopping\n",
            "Min val loss: 0.5059232115745544\n",
            "650/650 [==============================] - 3s 3ms/step\n",
            "Fold 10\n",
            "Epoch 1/300\n",
            "504/504 [==============================] - 16s 16ms/step - loss: 0.5227 - binary_accuracy: 0.7839 - val_loss: 0.5136 - val_binary_accuracy: 0.7879 - lr: 0.0100\n",
            "Epoch 2/300\n",
            "504/504 [==============================] - 7s 15ms/step - loss: 0.5131 - binary_accuracy: 0.7868 - val_loss: 0.5106 - val_binary_accuracy: 0.7879 - lr: 0.0100\n",
            "Epoch 3/300\n",
            "504/504 [==============================] - 7s 14ms/step - loss: 0.5122 - binary_accuracy: 0.7870 - val_loss: 0.5089 - val_binary_accuracy: 0.7879 - lr: 0.0100\n",
            "Epoch 4/300\n",
            "504/504 [==============================] - 8s 15ms/step - loss: 0.5120 - binary_accuracy: 0.7871 - val_loss: 0.5122 - val_binary_accuracy: 0.7879 - lr: 0.0100\n",
            "Epoch 5/300\n",
            "504/504 [==============================] - 8s 15ms/step - loss: 0.5121 - binary_accuracy: 0.7871 - val_loss: 0.5136 - val_binary_accuracy: 0.7879 - lr: 0.0100\n",
            "Epoch 6/300\n",
            "504/504 [==============================] - 7s 14ms/step - loss: 0.5113 - binary_accuracy: 0.7871 - val_loss: 0.5095 - val_binary_accuracy: 0.7879 - lr: 0.0100\n",
            "Epoch 7/300\n",
            "504/504 [==============================] - 7s 15ms/step - loss: 0.5114 - binary_accuracy: 0.7871 - val_loss: 0.5156 - val_binary_accuracy: 0.7879 - lr: 0.0100\n",
            "Epoch 8/300\n",
            "503/504 [============================>.] - ETA: 0s - loss: 0.5122 - binary_accuracy: 0.7870\n",
            "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "504/504 [==============================] - 8s 16ms/step - loss: 0.5121 - binary_accuracy: 0.7871 - val_loss: 0.5101 - val_binary_accuracy: 0.7879 - lr: 0.0100\n",
            "Epoch 9/300\n",
            "504/504 [==============================] - 7s 14ms/step - loss: 0.5105 - binary_accuracy: 0.7871 - val_loss: 0.5086 - val_binary_accuracy: 0.7879 - lr: 0.0050\n",
            "Epoch 10/300\n",
            "504/504 [==============================] - 7s 15ms/step - loss: 0.5108 - binary_accuracy: 0.7871 - val_loss: 0.5096 - val_binary_accuracy: 0.7879 - lr: 0.0050\n",
            "Epoch 11/300\n",
            "504/504 [==============================] - 7s 14ms/step - loss: 0.5103 - binary_accuracy: 0.7871 - val_loss: 0.5094 - val_binary_accuracy: 0.7879 - lr: 0.0050\n",
            "Epoch 12/300\n",
            "504/504 [==============================] - 7s 15ms/step - loss: 0.5103 - binary_accuracy: 0.7871 - val_loss: 0.5087 - val_binary_accuracy: 0.7879 - lr: 0.0050\n",
            "Epoch 13/300\n",
            "504/504 [==============================] - 7s 14ms/step - loss: 0.5123 - binary_accuracy: 0.7871 - val_loss: 0.5089 - val_binary_accuracy: 0.7879 - lr: 0.0050\n",
            "Epoch 14/300\n",
            "502/504 [============================>.] - ETA: 0s - loss: 0.5109 - binary_accuracy: 0.7869\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n",
            "504/504 [==============================] - 9s 17ms/step - loss: 0.5106 - binary_accuracy: 0.7870 - val_loss: 0.5106 - val_binary_accuracy: 0.7879 - lr: 0.0050\n",
            "Epoch 15/300\n",
            "504/504 [==============================] - 8s 15ms/step - loss: 0.5099 - binary_accuracy: 0.7871 - val_loss: 0.5085 - val_binary_accuracy: 0.7879 - lr: 0.0025\n",
            "Epoch 16/300\n",
            "504/504 [==============================] - 7s 15ms/step - loss: 0.5102 - binary_accuracy: 0.7871 - val_loss: 0.5091 - val_binary_accuracy: 0.7879 - lr: 0.0025\n",
            "Epoch 17/300\n",
            "504/504 [==============================] - 7s 14ms/step - loss: 0.5101 - binary_accuracy: 0.7871 - val_loss: 0.5086 - val_binary_accuracy: 0.7879 - lr: 0.0025\n",
            "Epoch 18/300\n",
            "504/504 [==============================] - 7s 15ms/step - loss: 0.5098 - binary_accuracy: 0.7871 - val_loss: 0.5091 - val_binary_accuracy: 0.7879 - lr: 0.0025\n",
            "Epoch 19/300\n",
            "504/504 [==============================] - ETA: 0s - loss: 0.5102 - binary_accuracy: 0.7871\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n",
            "504/504 [==============================] - 8s 16ms/step - loss: 0.5102 - binary_accuracy: 0.7871 - val_loss: 0.5100 - val_binary_accuracy: 0.7879 - lr: 0.0025\n",
            "Epoch 20/300\n",
            "504/504 [==============================] - 8s 16ms/step - loss: 0.5102 - binary_accuracy: 0.7871 - val_loss: 0.5088 - val_binary_accuracy: 0.7879 - lr: 0.0012\n",
            "Epoch 21/300\n",
            "504/504 [==============================] - 8s 15ms/step - loss: 0.5098 - binary_accuracy: 0.7871 - val_loss: 0.5092 - val_binary_accuracy: 0.7879 - lr: 0.0012\n",
            "Epoch 22/300\n",
            "504/504 [==============================] - 8s 16ms/step - loss: 0.5102 - binary_accuracy: 0.7871 - val_loss: 0.5088 - val_binary_accuracy: 0.7879 - lr: 0.0012\n",
            "Epoch 23/300\n",
            "504/504 [==============================] - 8s 16ms/step - loss: 0.5102 - binary_accuracy: 0.7871 - val_loss: 0.5086 - val_binary_accuracy: 0.7879 - lr: 0.0012\n",
            "Epoch 24/300\n",
            "501/504 [============================>.] - ETA: 0s - loss: 0.5097 - binary_accuracy: 0.7871\n",
            "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n",
            "504/504 [==============================] - 7s 14ms/step - loss: 0.5097 - binary_accuracy: 0.7871 - val_loss: 0.5087 - val_binary_accuracy: 0.7879 - lr: 0.0012\n",
            "Epoch 25/300\n",
            "504/504 [==============================] - 7s 14ms/step - loss: 0.5091 - binary_accuracy: 0.7871 - val_loss: 0.5086 - val_binary_accuracy: 0.7879 - lr: 6.2500e-04\n",
            "Epoch 26/300\n",
            "504/504 [==============================] - 7s 14ms/step - loss: 0.5099 - binary_accuracy: 0.7871 - val_loss: 0.5087 - val_binary_accuracy: 0.7879 - lr: 6.2500e-04\n",
            "Epoch 27/300\n",
            "501/504 [============================>.] - ETA: 0s - loss: 0.5095 - binary_accuracy: 0.7871Restoring model weights from the end of the best epoch: 15.\n",
            "504/504 [==============================] - 8s 15ms/step - loss: 0.5095 - binary_accuracy: 0.7871 - val_loss: 0.5086 - val_binary_accuracy: 0.7879 - lr: 6.2500e-04\n",
            "Epoch 27: early stopping\n",
            "Min val loss: 0.5085306763648987\n",
            "650/650 [==============================] - 3s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sub = pd.DataFrame({'id':df_test['id'], 'failure':test_predictions.reshape(-1)})\n",
        "sub.to_csv('TF_NN_cross.csv', index=False)"
      ],
      "metadata": {
        "id": "KaHieIAcwG8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions submit -c tabular-playground-series-aug-2022 -f TF_NN_cross.csv -m \"Tensorflow NN cross\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QKQTcCwwU2k",
        "outputId": "0b87816a-2906-4d05-c335-0a78fa86d73a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 520k/520k [00:03<00:00, 160kB/s]\n",
            "Successfully submitted to Tabular Playground Series - Aug 2022"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip models.zip ./*.h5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-i8gxcqDQHh",
        "outputId": "9513a7bb-4048-494f-dc23-9bd41b8ebf8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: model0.h5 (deflated 71%)\n",
            "  adding: model1.h5 (deflated 71%)\n",
            "  adding: model2.h5 (deflated 71%)\n",
            "  adding: model3.h5 (deflated 71%)\n",
            "  adding: model4.h5 (deflated 71%)\n",
            "  adding: model5.h5 (deflated 71%)\n",
            "  adding: model6.h5 (deflated 71%)\n",
            "  adding: model7.h5 (deflated 71%)\n",
            "  adding: model8.h5 (deflated 71%)\n",
            "  adding: model9.h5 (deflated 71%)\n"
          ]
        }
      ]
    }
  ]
}